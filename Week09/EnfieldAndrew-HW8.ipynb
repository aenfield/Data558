{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-30T15:29:09.500274",
     "start_time": "2017-05-30T15:29:09.494274"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# general\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import importlib\n",
    "\n",
    "# first used in exercise one\n",
    "import kernelsvm as svm\n",
    "from sklearn.metrics.pairwise import linear_kernel, polynomial_kernel\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'kernelsvm' from '/Users/andrewenfield/work/github/Data558/Week09/kernelsvm.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-30T15:28:43.281144",
     "start_time": "2017-05-30T15:28:43.260642"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  2],\n",
       "       [ 0,  1],\n",
       "       [-1, -2]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_simple = np.array([3,2,0,1,-1,-2]).reshape(3,2)\n",
    "x_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Per the request in the \"Collaboration policy\" note, I've discussed at least part of this assignment with many of the MS employees in the class, including Abhishek, Geoff, Suman, and Charles. (Different weeks/different assignments have different people, depending upon who attends our study groups, but I'll probably just include this blurb w/ each homework since it's generally correct.) I've also gotten input from the discussion board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "_Compute the gradient ∇F(α) of F._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![FirstProb](FirstProb.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write a function computegram that computes, for any set of datapoints x1, . . . , xn, the kernel matrix K._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I implemented the computegram_linear function, and all of the supporting functions including the gradient and objective functions, in the file kernelsvm.py, which I imported into this notebook with the alias svm. I also include my (relatively minimal) unit tests, in kernelsvm-test.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  2, -7],\n",
       "       [ 2,  1, -2],\n",
       "       [-7, -2,  5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.computegram_linear(x_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[196,   9,  36],\n",
       "       [  9,   4,   1],\n",
       "       [ 36,   1,  36]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.computegram_polynomial(x_simple, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write a function kerneleval that computes, for any set of datapoints x1, . . . , xn and a new datapoint x⋆, the vector of kernel evaluations [k(x1, x⋆), . . . , k(xn, x⋆)]T._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I implemented this function in kernelsvm.py.\n",
    "\n",
    "My understanding here is that I'm not using the kernel matrix - that is, the reference to 'kernel evaluation' means to use the kernel _function_, not the kernel matrix. I think this is just (part of - since no alpha weighting yet) the predict step, which - for a linear kernel - is the sum of the inner products between each observation and the value to be predicted, weighted by each learned value of alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  2, -6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.kerneleval_linear(x_simple, np.array([2,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Consider the MNIST dataset. You can find instructions on how to download it here: http://scikit-learn.org/stable/datasets/mldata.html. Pick two classes of your choice. Your are going to work on the dataset consisting of the data from these two classes. Standardize the data, if you have not done so already._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist.data.shape, mnist.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use 1 and 8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14702, 784), (14702,), array([ 1.,  8.]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_and_eights = (mnist.target == 1) | (mnist.target == 8)\n",
    "X = mnist.data[ones_and_eights]\n",
    "y = mnist.target[ones_and_eights]\n",
    "X.shape, y.shape, np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewenfield/miniconda3/envs/data558/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype uint8 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14702, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled = preprocessing.scale(X)\n",
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11026, 784), (3676, 784), (11026,), (3676,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_train, X_scaled_test, y_train, y_test = train_test_split(X_scaled, y)\n",
    "X_scaled_train.shape, X_scaled_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write a function mysvm that implements the fast gradient algorithm to train the kernel support vector machine with the squared hinge loss. The function takes as input the initial step-size value for the backtracking rule and a maximum number of iterations._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted above, I implemented this in the kernelsvm.py file. Instead of creating a function named mysvm, I just call my fastgradalgo function and pass in references to the kernel SVM gradient and objective functions (which are also implemented in the same file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Train your kernel support vector machine with the squared hinge loss and the polyno- mial kernel of order 7 on the the MNIST dataset, tuning the regularization parameter λ using cross-validation._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried both my fast gradient descent and gradient descent implementations with the kernel SVM gradient and objective functions, but haven't been able to get it to work, from what I can tell. Running for even just 10 iterations takes much longer than it should, to start with - this shouldn't be the case, I think (?): it should run more quickly?. And then the coefficients that I get make me think the algorithm hasn't converged - sometimes they're massively large and other times very small (effectively zero).\n",
    "\n",
    "While it took until the end of the last part of the last exercise of the last homework, I'm going to throw in the towel on this one. I still have work to do to finish the final project report, and don't have more time to spend on this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'kernelsvm' from '/Users/andrewenfield/work/github/Data558/Week09/kernelsvm.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_init = 0.01\n",
    "max_iters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11016</th>\n",
       "      <th>11017</th>\n",
       "      <th>11018</th>\n",
       "      <th>11019</th>\n",
       "      <th>11020</th>\n",
       "      <th>11021</th>\n",
       "      <th>11022</th>\n",
       "      <th>11023</th>\n",
       "      <th>11024</th>\n",
       "      <th>11025</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-5.462164e-08</td>\n",
       "      <td>-1.401092e-07</td>\n",
       "      <td>-5.213958e-08</td>\n",
       "      <td>1.071975e-07</td>\n",
       "      <td>-1.389692e-08</td>\n",
       "      <td>-3.648095e-08</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-6.721888e-08</td>\n",
       "      <td>-5.752141e-08</td>\n",
       "      <td>-8.009989e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.142063e-08</td>\n",
       "      <td>7.656160e-08</td>\n",
       "      <td>8.296727e-07</td>\n",
       "      <td>-4.297519e-08</td>\n",
       "      <td>8.620134e-07</td>\n",
       "      <td>2.374047e-08</td>\n",
       "      <td>4.307277e-07</td>\n",
       "      <td>-5.100345e-07</td>\n",
       "      <td>-5.320968e-08</td>\n",
       "      <td>1.450999e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-5.462164e-08</td>\n",
       "      <td>-1.401092e-07</td>\n",
       "      <td>-5.213958e-08</td>\n",
       "      <td>1.071975e-07</td>\n",
       "      <td>-1.389692e-08</td>\n",
       "      <td>-3.648095e-08</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-6.721888e-08</td>\n",
       "      <td>-5.752141e-08</td>\n",
       "      <td>-8.009989e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.142063e-08</td>\n",
       "      <td>7.656160e-08</td>\n",
       "      <td>8.296727e-07</td>\n",
       "      <td>-4.297519e-08</td>\n",
       "      <td>8.620134e-07</td>\n",
       "      <td>2.374047e-08</td>\n",
       "      <td>4.307277e-07</td>\n",
       "      <td>-5.100345e-07</td>\n",
       "      <td>-5.320968e-08</td>\n",
       "      <td>1.450999e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-5.462164e-08</td>\n",
       "      <td>-1.401092e-07</td>\n",
       "      <td>-5.213958e-08</td>\n",
       "      <td>1.071975e-07</td>\n",
       "      <td>-1.389692e-08</td>\n",
       "      <td>-3.648095e-08</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-6.721888e-08</td>\n",
       "      <td>-5.752141e-08</td>\n",
       "      <td>-8.009989e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.142063e-08</td>\n",
       "      <td>7.656160e-08</td>\n",
       "      <td>8.296727e-07</td>\n",
       "      <td>-4.297519e-08</td>\n",
       "      <td>8.620134e-07</td>\n",
       "      <td>2.374047e-08</td>\n",
       "      <td>4.307277e-07</td>\n",
       "      <td>-5.100345e-07</td>\n",
       "      <td>-5.320968e-08</td>\n",
       "      <td>1.450999e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 11026 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0             1             2             3             4      \\\n",
       "8  -5.462164e-08 -1.401092e-07 -5.213958e-08  1.071975e-07 -1.389692e-08   \n",
       "9  -5.462164e-08 -1.401092e-07 -5.213958e-08  1.071975e-07 -1.389692e-08   \n",
       "10 -5.462164e-08 -1.401092e-07 -5.213958e-08  1.071975e-07 -1.389692e-08   \n",
       "\n",
       "           5         6             7             8             9      \\\n",
       "8  -3.648095e-08  0.000001 -6.721888e-08 -5.752141e-08 -8.009989e-08   \n",
       "9  -3.648095e-08  0.000001 -6.721888e-08 -5.752141e-08 -8.009989e-08   \n",
       "10 -3.648095e-08  0.000001 -6.721888e-08 -5.752141e-08 -8.009989e-08   \n",
       "\n",
       "        ...              11016         11017         11018         11019  \\\n",
       "8       ...      -6.142063e-08  7.656160e-08  8.296727e-07 -4.297519e-08   \n",
       "9       ...      -6.142063e-08  7.656160e-08  8.296727e-07 -4.297519e-08   \n",
       "10      ...      -6.142063e-08  7.656160e-08  8.296727e-07 -4.297519e-08   \n",
       "\n",
       "           11020         11021         11022         11023         11024  \\\n",
       "8   8.620134e-07  2.374047e-08  4.307277e-07 -5.100345e-07 -5.320968e-08   \n",
       "9   8.620134e-07  2.374047e-08  4.307277e-07 -5.100345e-07 -5.320968e-08   \n",
       "10  8.620134e-07  2.374047e-08  4.307277e-07 -5.100345e-07 -5.320968e-08   \n",
       "\n",
       "           11025  \n",
       "8   1.450999e-08  \n",
       "9   1.450999e-08  \n",
       "10  1.450999e-08  \n",
       "\n",
       "[3 rows x 11026 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = svm.fastgradalgo(\n",
    "    svm.computegram_linear(X_scaled_train), \n",
    "    y_train, t_init=t_init, \n",
    "    grad_func = svm.compute_kernelsvm_gradient, \n",
    "    obj_func = svm.compute_kernelsvm_objective, \n",
    "    lam=1, max_iter=max_iters, t_func=svm.backtracking)\n",
    "results[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11016</th>\n",
       "      <th>11017</th>\n",
       "      <th>11018</th>\n",
       "      <th>11019</th>\n",
       "      <th>11020</th>\n",
       "      <th>11021</th>\n",
       "      <th>11022</th>\n",
       "      <th>11023</th>\n",
       "      <th>11024</th>\n",
       "      <th>11025</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-6.303448e+38</td>\n",
       "      <td>1.925032e+38</td>\n",
       "      <td>-8.382886e+38</td>\n",
       "      <td>4.803830e+39</td>\n",
       "      <td>-3.989533e+38</td>\n",
       "      <td>-8.090180e+38</td>\n",
       "      <td>1.419069e+40</td>\n",
       "      <td>-6.314012e+38</td>\n",
       "      <td>-7.860306e+38</td>\n",
       "      <td>-7.417590e+38</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.610042e+38</td>\n",
       "      <td>4.608151e+39</td>\n",
       "      <td>4.471622e+39</td>\n",
       "      <td>-8.650836e+38</td>\n",
       "      <td>9.597904e+39</td>\n",
       "      <td>-3.020028e+38</td>\n",
       "      <td>6.265127e+39</td>\n",
       "      <td>-3.468848e+39</td>\n",
       "      <td>-4.958168e+38</td>\n",
       "      <td>-6.282597e+38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.362395e+45</td>\n",
       "      <td>-5.698541e+44</td>\n",
       "      <td>1.838750e+45</td>\n",
       "      <td>-1.178439e+46</td>\n",
       "      <td>6.528313e+44</td>\n",
       "      <td>1.767523e+45</td>\n",
       "      <td>-2.181735e+46</td>\n",
       "      <td>1.325367e+45</td>\n",
       "      <td>1.722792e+45</td>\n",
       "      <td>1.666910e+45</td>\n",
       "      <td>...</td>\n",
       "      <td>1.946797e+45</td>\n",
       "      <td>-1.236126e+46</td>\n",
       "      <td>-1.141594e+46</td>\n",
       "      <td>1.909282e+45</td>\n",
       "      <td>-1.519295e+46</td>\n",
       "      <td>1.900969e+44</td>\n",
       "      <td>-1.315504e+46</td>\n",
       "      <td>6.244272e+45</td>\n",
       "      <td>9.966048e+44</td>\n",
       "      <td>1.161997e+45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-3.123210e+52</td>\n",
       "      <td>9.547564e+51</td>\n",
       "      <td>-4.153328e+52</td>\n",
       "      <td>2.380498e+53</td>\n",
       "      <td>-1.976404e+52</td>\n",
       "      <td>-4.008452e+52</td>\n",
       "      <td>7.030566e+53</td>\n",
       "      <td>-3.128325e+52</td>\n",
       "      <td>-3.894441e+52</td>\n",
       "      <td>-3.675255e+52</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.266054e+52</td>\n",
       "      <td>2.283561e+53</td>\n",
       "      <td>2.213490e+53</td>\n",
       "      <td>-4.286134e+52</td>\n",
       "      <td>4.756941e+53</td>\n",
       "      <td>-1.497347e+52</td>\n",
       "      <td>3.104920e+53</td>\n",
       "      <td>-1.719044e+53</td>\n",
       "      <td>-2.456464e+52</td>\n",
       "      <td>-3.113095e+52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 11026 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0             1             2             3             4      \\\n",
       "7 -6.303448e+38  1.925032e+38 -8.382886e+38  4.803830e+39 -3.989533e+38   \n",
       "8  1.362395e+45 -5.698541e+44  1.838750e+45 -1.178439e+46  6.528313e+44   \n",
       "9 -3.123210e+52  9.547564e+51 -4.153328e+52  2.380498e+53 -1.976404e+52   \n",
       "\n",
       "          5             6             7             8             9      \\\n",
       "7 -8.090180e+38  1.419069e+40 -6.314012e+38 -7.860306e+38 -7.417590e+38   \n",
       "8  1.767523e+45 -2.181735e+46  1.325367e+45  1.722792e+45  1.666910e+45   \n",
       "9 -4.008452e+52  7.030566e+53 -3.128325e+52 -3.894441e+52 -3.675255e+52   \n",
       "\n",
       "       ...              11016         11017         11018         11019  \\\n",
       "7      ...      -8.610042e+38  4.608151e+39  4.471622e+39 -8.650836e+38   \n",
       "8      ...       1.946797e+45 -1.236126e+46 -1.141594e+46  1.909282e+45   \n",
       "9      ...      -4.266054e+52  2.283561e+53  2.213490e+53 -4.286134e+52   \n",
       "\n",
       "          11020         11021         11022         11023         11024  \\\n",
       "7  9.597904e+39 -3.020028e+38  6.265127e+39 -3.468848e+39 -4.958168e+38   \n",
       "8 -1.519295e+46  1.900969e+44 -1.315504e+46  6.244272e+45  9.966048e+44   \n",
       "9  4.756941e+53 -1.497347e+52  3.104920e+53 -1.719044e+53 -2.456464e+52   \n",
       "\n",
       "          11025  \n",
       "7 -6.282597e+38  \n",
       "8  1.161997e+45  \n",
       "9 -3.113095e+52  \n",
       "\n",
       "[3 rows x 11026 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_regular = svm.graddescent(np.zeros(len(X_scaled_train)), \n",
    "                svm.computegram_linear(X_scaled_train), y_train,\n",
    "                t_init=t_init,\n",
    "                grad_func = svm.compute_kernelsvm_gradient, \n",
    "                obj_func = svm.compute_kernelsvm_objective, \n",
    "                lam=1, max_iter=max_iters)\n",
    "results_regular[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Compare the performance of kernel SVMs with different kernels (polynomial kernels with different orders, Gaussian RBF with different bandwidths, etc.)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I wrote a computegram_polynomial function to handle polynomial kernels with different orders, and would have been able write the code for a function to do the same for radial basis functions. However, since I can't get my fast gradient or straightforward (not fast) gradient descent algorithm to work with my implementations of the kernel SVM gradient and objective functions, I'm going to call it a day here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
