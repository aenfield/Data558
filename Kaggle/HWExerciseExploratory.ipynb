{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "%matplotlib inline \n",
    "\n",
    "from sklearn import model_selection \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import preprocessing # for scale\n",
    "\n",
    "import pickle\n",
    "import importlib\n",
    "\n",
    "import finalproj as fp\n",
    "import corinne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'corinne' from '/Users/andrewenfield/work/github/Data558/Kaggle/corinne.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(fp)\n",
    "importlib.reload(corinne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4320 4320\n"
     ]
    }
   ],
   "source": [
    "features_train = np.array(pickle.load(open('features_train', 'rb')))\n",
    "labels_train = np.array(pickle.load(open('labels_train', 'rb')))\n",
    "print(len(features_train), len(labels_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4320, 2048)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled = preprocessing.scale(features_train)\n",
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "_Pick two classes of your choice from the dataset. Train an L2-regularized logistic regression classiﬁer on the training set using your own fast gradient algorithm with λ = 1. Plot, with diﬀerent colors, the misclassiﬁcation error on the training set and on the validation set vs iterations._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I'll pick 086, Pacific Loon, and 087, Mallard, as the two classes.\n",
    "\n",
    "Per Zaid's answer on 5/27, in this problem I'm considering just the subset of the data that has these two classes. I pull the data and train/test a binary classifer. I only use the 60 observations for the two chosen birds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690,\n",
       "        1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701,\n",
       "        1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712,\n",
       "        1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723,\n",
       "        1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734,\n",
       "        1735, 1736, 1737, 1738, 1739]),)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_twoclasses = np.where((labels_train == '086.Pacific_Loon') | (labels_train == '087.Mallard'))\n",
    "indices_twoclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 2048)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_twoclasses = X_scaled[indices_twoclasses]\n",
    "X_twoclasses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_twoclasses = np.where(labels_train[indices_twoclasses] == '086.Pacific_Loon', 1, -1)\n",
    "y_twoclasses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_probability(logodds):\n",
    "    return 1 / (1 + np.exp(-logodds))\n",
    "    #return np.exp(logodds) / (1 + np.exp(logodds))\n",
    "\n",
    "def get_accuracy(beta_coefs, X, y_actual, prob_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Return the classification accuracy given a set of coefficients, in \n",
    "    beta_coefs, and observations, in X, compared to actual/known values \n",
    "    in y_actual. The threshold parameter defines the value above which the\n",
    "    predicted value is considered a positive example.\n",
    "    \"\"\"\n",
    "    y_pred = X.dot(beta_coefs.T).ravel() # ravel to convert to vector\n",
    "    \n",
    "    # for logistic regression convert to a prob and use a prob threshold\n",
    "    probs = get_probability(y_pred)\n",
    "    y_thresholded = np.where(probs > prob_threshold, 1, -1)\n",
    "    \n",
    "    return accuracy_score(y_actual, y_thresholded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42, 2048), (18, 2048), (42,), (18,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_twoclasses_train, X_twoclasses_test, y_twoclasses_train, y_twoclasses_test = model_selection.train_test_split(\n",
    "    X_twoclasses, y_twoclasses, test_size=0.3)\n",
    "X_twoclasses_train.shape, X_twoclasses_test.shape, y_twoclasses_train.shape, y_twoclasses_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_init = 0.01\n",
    "max_iters = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.006024</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>-0.003482</td>\n",
       "      <td>-0.001739</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.001852</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>-0.002971</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002482</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.003860</td>\n",
       "      <td>-0.009474</td>\n",
       "      <td>0.006331</td>\n",
       "      <td>0.007518</td>\n",
       "      <td>-0.009262</td>\n",
       "      <td>-0.012654</td>\n",
       "      <td>-0.002804</td>\n",
       "      <td>0.002661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.006024</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>-0.003481</td>\n",
       "      <td>-0.001739</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.001855</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>-0.002972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002482</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.003858</td>\n",
       "      <td>-0.009473</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>0.007518</td>\n",
       "      <td>-0.009264</td>\n",
       "      <td>-0.012652</td>\n",
       "      <td>-0.002803</td>\n",
       "      <td>0.002660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-0.006023</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>-0.003481</td>\n",
       "      <td>-0.001740</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.001858</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>-0.002974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002482</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>-0.009473</td>\n",
       "      <td>0.006328</td>\n",
       "      <td>0.007518</td>\n",
       "      <td>-0.009265</td>\n",
       "      <td>-0.012650</td>\n",
       "      <td>-0.002802</td>\n",
       "      <td>0.002659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6     \\\n",
       "98  -0.006024  0.000631  0.004123 -0.003482 -0.001739 -0.000461 -0.001852   \n",
       "99  -0.006024  0.000632  0.004123 -0.003481 -0.001739 -0.000461 -0.001855   \n",
       "100 -0.006023  0.000633  0.004124 -0.003481 -0.001740 -0.000461 -0.001858   \n",
       "\n",
       "         7         8         9       ...         2038      2039      2040  \\\n",
       "98   0.001646  0.000242 -0.002971    ...    -0.002482  0.000130  0.003860   \n",
       "99   0.001646  0.000241 -0.002972    ...    -0.002482  0.000128  0.003858   \n",
       "100  0.001645  0.000241 -0.002974    ...    -0.002482  0.000127  0.003857   \n",
       "\n",
       "         2041      2042      2043      2044      2045      2046      2047  \n",
       "98  -0.009474  0.006331  0.007518 -0.009262 -0.012654 -0.002804  0.002661  \n",
       "99  -0.009473  0.006330  0.007518 -0.009264 -0.012652 -0.002803  0.002660  \n",
       "100 -0.009473  0.006328  0.007518 -0.009265 -0.012650 -0.002802  0.002659  \n",
       "\n",
       "[3 rows x 2048 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = fp.fastgradalgo(\n",
    "    X_twoclasses_train, y_twoclasses_train, t_init=t_init, \n",
    "    grad_func = fp.compute_gradient_logistic_regression, \n",
    "    obj_func = fp.compute_objective_logistic_regression, \n",
    "    lam=1, max_iter=max_iters)\n",
    "results[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n",
      "Misclassification error: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# note use of the held out test data to get the performance metrics\n",
    "accuracy = get_accuracy(fp.get_final_coefs(results), X_twoclasses_test, y_twoclasses_test)\n",
    "print(\"Accuracy: {0:.1%}\".format(accuracy))\n",
    "print(\"Misclassification error: {0:.1%}\".format(1 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_objective_values(beta_results_df, X, y, lam):\n",
    "    return beta_results_df.apply(lambda r: fp.compute_objective_logistic_regression(r.values, \n",
    "                                                    X, y, lam), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.246583</td>\n",
       "      <td>0.327964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.149881</td>\n",
       "      <td>0.144143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Train  Validation\n",
       "0  0.693147    0.693147\n",
       "1  0.246583    0.327964\n",
       "2  0.149881    0.144143"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_vals = pd.DataFrame({'Train': get_objective_values(results, X_twoclasses_train, y_twoclasses_train, 1),\n",
    "              'Validation': get_objective_values(results, X_twoclasses_test, y_twoclasses_test, 1)})\n",
    "obj_vals[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x106d819b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAETCAYAAAAs4pGmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcHFW5//FPdXXPTJbJPmFH9geEGJAIBCPbJT8UZBEQ\nBf1xQVEWwZ/ovV4UrywGEQXZJMguIC4gILIIorImRmUPSx6IQADDEoImIUxmppffH1U93TP09HSS\nqZ505vt+Eaa7quv0UyeZeuqcU3UqKBQKiIiI9JYa7ABERGTNpAQhIiIVKUGIiEhFShAiIlKREoSI\niFSkBCEiIhUpQcj7mNlxZvakmT1rZs+Y2fVmtnHZ+pfNbEqF7aaY2W9W43uPMbMTymI4ZVXL6lXu\n9mb2DzN7zMw2GYgyy8r+rpkdGL8+08yOHKByjzKzO1Zj+wPM7KL49X5mduZAxFVWfiL7LWuW9GAH\nIGsWMzsXmAx80t1fNbMU8HngL2a2s7u/1te27v4IcOhqfP004Om4rJ+uRjm9HQDc5+7HDGCZRXsB\nzwK4+3cTKH+VuPvvgN/Fbz8CjBvgr1gj91sGVqAb5aTIzDYE5gEbufu/eq27EEi7+1fM7GXgPqJE\n0gyc5+5Xm9kewE/cfTszawLOAXYHQuBx4KvuvtTMtgIuAyYCeWAG0AlcBbQD3wfagAlEB7nz3H1S\nHMcY4CVgM2A48BNgYyAD/Mrdv98r7s8B58Ux/AG4FzjU3T8Zrz+q+N7MfgYsBSYBG8V18Vl3f9fM\ndgYuAkbEsf4XsE28j4uArwMHAk+7+7lm9jHgR3GMncB33P3u+Ps+Fe/3lvG6I9396V5xHwWcFJe9\nPrAA+BLQBDwDbOjuS8wsABz4tLs/2Wv7Q4HvAbfF+3+5u59qZl8ETiDqQVgMnOju8+L9HwdsDtwR\n/31cAoyMY3gC+AzwxaT2W9Ys6mKScjsDz/VODrE/Ep3hF7W7+4eB6cAPzGzbXp8/BcgCO7r7ZGAh\n8IN43a+Am9x9W2BfooTwJ6JkcL67X1JWzr3AyLIurcOBO+MYrweudvcdgZ2Avc3ssPIg3P0G4KfA\nr939czXUwY7Ax4kO/usDnzazDPBb4Ex3347oQH0hcCnwCPDf7n5rsQAzGw/8Bvh/7v4h4D+Bn5vZ\npvFHdgdOisuaBfx3H7FsRXTw/hAwF7jQ3V+J66q4L3sCi8uTQ6/9/2vZ/p9qZrvH8XzM3XcAfgjc\nUrbJcHff1t3/J97Pa919KrAFsCmwX/z3k+R+yxpCCUJ6y/SxvBkob25eBuDuC4F7gP/o9flPEp1Z\nPm5mTwAHAR80s3FELY8r4+1fdffN3X1ppS919wLRmexR8aKjgSvNbATRAed7cflziFoS29e+qxXd\n7e4d7t5FdFAeR9SiyLn7nXFMj7r7JHfP91HGzsD8+OCMuz9DdEDcI17/aFlX3WP03f3zR3efH7++\niigZQ3RW/6X49bFEiapW+xEd7GfH9fZDYFz89wLwcNln/wdYZGbfjL9jfaLWRF8Gar9lDaExCCk3\nB9jSzNZ19zd6rdsTmF32Plf2OgC6en0+JDqT/D2AmY0EWohaFVCWbMzMgFeqxHUNUaK5Ehjj7veb\n2aj4e3d19/ficiYAK/rZx0K8XVFTr/XtFT6bpWdyxMy2I+qCqqTSiVeKKPl29vEdlfRVx38EhpvZ\nfwC7EZ2p1yoEro9bCMRjTOsDxVbju2Wf/SXRMeJG4E6iBNxXrDBw+y1rCLUgpJu7/5Oon/2XZrZB\ncbmZHQ0cQtTvXHRUvG5jojPbP/Uq7h7gRDNrig9CVwBnxy2FR4kPama2EdFZ5miiA/H7WjBxXH8l\narUUWx5LiRLa1+NyxsTlHNjPbi4CtjOzFjNLA/v383mI+vgLZjY9/q4PA38m+v2pFPOc6GO2U/z5\nbYkO5PfX8F3l9iy7eux44PfQ3aqaSVQXv3D3/pJieYx/AA43s/Xi98fx/r+7on2IutV+TXRA35ko\nwfQus2ig9lvWEEoQ0oO7fwv4OXCbmT1tZi8AewNT3X1B2UdbzOwx4C6ifuXnexX1PeBlosHpZ4nO\nFr8RrzsCOMzMngRuB46JWyy/B75qZt+qENoVwA7AtWXLjgB2MbO5RAnkl/GYQzV/AB4gOvt/iKgb\nqSp37wAOBk6Lu2V+Chzs7p1x/Oea2X+Wff5t4NPAxXFsvwCOrlBH/XkKuNrMniY6e/962brriAbS\nL6uhnD8BB5jZxe5+D1Giv9fMniKqw4PjpNPbt4FbzewRon1+gKh7CpLdb1lD6ComGTBmdgBwqrvv\nPNixrO3M7HCiq4A+MdixyNpLYxAyIMzsROA7gK6JT5iZ3Q+sQ9TtJ5IYtSBERKQijUGIiEhFShAi\nIlJRw4xBZLO5wr/+9d5gh7FGGDt2OKqLiOqiRHVRorooaWtrXeX7TRqmBZFOh/1/aIhQXZSoLkpU\nFyWqi4HRMAlCRETqSwlCREQqUoIQEZGKEhukjuffmUk0c2cH0XQK8+N16xJN+Vy0PXDKAD8kRkRE\nVkOSVzEdBLS4+1Qz24XooS0HAsTz7uwBYGZTgbOI5toREZE1RJJdTNOAuwHcfQ5Q6RnGAXAxcLy7\n53qvFxGRwZNkC2IUsKTsfc7M0u6eLVu2P/CMu3stBba1tQ5kfA1NdVGiuihRXZSoLlZfkgliKVD+\nN5TqlRwAPk/06MZ+nf676zh+5wNJpTSu3tbWyqJFywY7jDWC6qJEdVGiuihZnUSZZIKYRdRCuDEe\ng6g07/4Uej6lrE/Ptv+Fl96eyuYT1x3AEEVESi6++Hzcn+OddxazYsUK1l9/A8aMGcuMGedU3e6F\nF5yHH36Qo4/+UtXPNZokE8StwHQzm030sJijzewIYKS7X25mbcDSPh5UUlF7tiOhUEVE4KSTTgbg\nrrtuZ8GClzn++JNq2m7LLY0tt7QkQxsUiSWI+IHux/VaPK9s/SJW8gHzHdnejz0WkbXVjX+ez9/n\nvbVK24ZhQC73/nPPj2w9kcP22qLCFn177LFHuPTSi8lkMhxwwKdobm7mlltuIpvNEgQB3//+ubz4\n4nxuu+1mzjjjbD772U8xadJkXnllAePGjWPGjB8Sho059UdDdeh3ZnsPYYiIJK+zs5OZM6/k4x/f\nj1dffYUf/ehCLr30KjbZZFP+9re/9PjswoX/5JhjjuOyy67h3//+F8899+wgRb36GmY2V4DOnFoQ\nIkPFYXttsdJn+0UDPUi98cYf6H49duw4Zsw4jeHDh7Ngwctst92Henx29OgxrLNONFY6ceI6dHY2\nbte4EoSISD9SqWjG7HfffZerrrqMm2++A4CTT/4KvZ/KGQSrPLv2GqfBEoS6mERk8IwYMYJJkyZz\n3HFHE4ZpWltbefvtRay33vqDHVoiGuaZ1If9+vjC9AkHctCHPjrYoQw6XeNdorooUV2UqC5KhsQD\ngwC68mpBiIjUixKEiIhU1FgJQmMQIiJ101gJIq+rmERE6qWhEkRWXUwiInXTUAlCYxAiIvXTUAki\nm9czhUQkOSee+GUeffTvPZZdcMG53H77b9/32ddfX8iXv3wUAKed9i26unp2gc+ZM5uzzjq9z+/q\n6OjoLveuu27n4YcfWL3gE9BQCSJXUAtCRJKz//4Hcffdd3a/7+rqYtash9h7732qbnfGGWeTyWRW\n6rveeWdxd4LYd9/9mTZt95UPOGENdSe1xiBEho5b5t/B429VeoxM/8JUQC7//puAd5g4iYO3+GSf\n2+2xx39w2WWXsGLFClpaWnjooQfYaaedmTfvWa655gry+Tzt7e2cdtqMHgnh0EP354YbfsPrry/k\n7LPPpKVlGMOGtdDaOgqAm2/+NQ88cB/t7e2MGTOG73//XK677mpefvml7nLHjx/PQQcdysUXn89T\nTz0BwPTpH+ewww7nrLNOJ5PJ8MYbr7N48dt8+9unY7b1KtXNymioFkS2oC4mEUlOc3Mzu+22Bw8+\neB8Ad931Ow488GBeeulFvvvd7/GTn1zO7rvvyX33/bHi9jNnXsgxxxzLhRfO7J7EL5/Ps2TJEi64\nYCZXXHEtuVyO5557hiOP/AKbbLJpj4cMzZr1EK+/vpDLL/8Zl156Fffeezf/+Md8ANZddz1+/OOf\ncMghn+F3v7sl4ZqINFQLQl1MIkPHwVt8surZfjWrM9XG/vt/iksuuZAddtiRZcuWsdVWW/Pmm29w\nwQU/Ytiw4Sxa9BaTJk2uuO0rr7zCNttsB8CkSduzYMHLpFIpMpkMp59+KsOGDeOtt94i28ejCxYs\neInJk7cnCALS6TTbbjuJl19+EaD7gUQTJ67D3LlPrtK+rayGakHk1IIQkYRtvvkWtLcv56abfsV+\n+x0AwDnnnMW3v30ap556OhMmtPW57aabbsrTTz8FwLx5zwAwf/4LPPjg/Zx55tmcfPI3KRTyAARB\nqvt10Qc+sGl391I2m+Xpp59iww03jj9f/1liG6oFkVeCEJE62G+/A7jkkou6p/XeZ59PcMIJX2LY\nsBbGjh3P228vqrjdiSeezIwZp/HLX17PmDFjaGpqZsMNN2LYsGEcf/wXABg/fgJvv72IbbedRFdX\nlpkzL6K5uRmAj370Yzz++KMce+zRdHV1sddee9dlrKEvDTWb66jc+pw9/WuDHcqg00yVJaqLEtVF\nieqiZMjM5ppDLQgRkXppmARRyAfklSBEROqmYRIEhRT5XgM6IiKSnMZJEPkUBXSZq4hIvTROgiik\nyAdqQYiI1EvDJIhCPkVBYxAiInWT2H0QZpYCZgKTgQ7gGHefX7b+I8CPgQB4A/i8u6/oq7ygoC4m\nEZF6SrIFcRDQ4u5TgVOA84orzCwArgCOdvdpwN3AB6qWVggpBGpBiIjUS5J3UhcP/Lj7HDObUrZu\nK2AxcLKZbQfc6e5erbCAkEKQp62tNbGAG4nqoUR1UaK6KFFdrL4kE8QoYEnZ+5yZpd09C0wAdgVO\nBOYDd5jZI+7+574KCwopCkGeN99aQipomKGTROgu0RLVRYnqokR1UbI6iTLJI+1SoDyyVJwcIGo9\nzHf359y9i6ilMaV3AeVShADk9FQ5EZG6SDJBzAL2BTCzXYDyJ3+8CIw0sy3i9x8DnqlWWBCHmtWU\n3yIidZFkF9OtwHQzm010pdLRZnYEMNLdLzezLwK/iAesZ7v7ndUKS8WhduWzDEswaBERiSSWINw9\nDxzXa/G8svV/BnaqtbxiF5MeOyoiUh8NM9qbCpQgRETqqWESRNjdgtAgtYhIPTROggii3rDOXNcg\nRyIiMjQ0UIKIWhAdWSUIEZF6UIIQEZGKGidBpNTFJCJST42TIOIxiC4lCBGRumiYBJFOFbuYdJmr\niEg9NFCCUBeTiEg9NUyCyHQnCLUgRETqoYESRAbQGISISL00ToII1YIQEamnBkoQcQsirxaEiEg9\nNE6CSBUvc1ULQkSkHhonQYSl50GIiEjyGiZBNKejLiZN9y0iUh8NkyC6r2JSghARqYuGSRBNGbUg\nRETqqWESRHM8BpEr6IFBIiL10DgJQmMQIiJ11TgJItMEQLagBCEiUg+NkyDSUYJQF5OISH00TIJo\nSqcpFJQgRETqpWESRCZMQT5FTl1MIiJ1kU6qYDNLATOByUAHcIy7zy9bfzJwDLAoXnSsu3ufgaZT\nUEiRVwtCRKQuEksQwEFAi7tPNbNdgPOAA8vW7wgc6e6P1lJYOgwgH5JDCUJEpB6S7GKaBtwN4O5z\ngCm91u8IfMvMHjazb/VXWDpMUSgEakGIiNRJki2IUcCSsvc5M0u7e3EQ4VfAJcBS4FYz+6S739FX\nYel0NAZRCHK0tbUmF3WDUB2UqC5KVBclqovV12+CMLMPAFcCmwC7ATcAX3D3l/vZdClQ/jeUKiYH\nMwuAC9x9Sfz+TmAHoO8EEUZjELlCJ4sWLesv7LVaW1vrkK+DItVFieqiRHVRsjqJspYupsuAHwHL\ngDeAXwLX1bDdLGBfgHgMYm7ZulHA02Y2Mk4WewFVxyLSYQryIXmNQYiI1EUtCWKCu/8BCNy94O5X\nEB3g+3MrsMLMZgPnAyeb2RFm9uW45fBt4D7gIeAZd7+rWmHpMKBQSFEgR6FQqOHrRURkddQyBtFu\nZhsCBQAzm0Z02WpV7p4Hjuu1eF7Z+uuB62sONL4PggDyhTxhENa6qYiIrIJaEsTXicYGNjezJ4Bx\nwGGJRlVBJr4PAqJnQoQpJQgRkST1myDc/e9m9hFgKyAE5rl7Z+KR9dLdgqA4o2tzvUMQERlSarmK\n6Rri7qWyZbj7FxKLqoIwTFGIWxCa0VVEJHm1dDHdX/Y6AxxA2VhCvYSpgKBHC0JERJJUSxfTteXv\nzewqoktY6y5ACUJEpF5WZaqNbYD1BjqQWqSIBqa78roXQkQkabWMQeSJxiCCeNEioN+5k5IQEFIA\nsvmuwfh6EZEhpZYupjXmmREpQnKoi0lEpB76TBBm9t1qG7r7mQMfTnWlBKEuJhGRpFVrQQRV1g2K\nVHz3tC5zFRFJXp8Jwt3PqLQ8nlxv08QiqqI4vUaXuphERBJXyyD1icD3gRFli18CtkgqqL6Ecbga\ngxARSV4tA9DfIHqu9K+BzYEvAn9NMqi+FFsQShAiIsmrJUG85e4vAU8Bk9z9Z4AlGlUfwiBqQaiL\nSUQkebUkiOVmtidRgtjfzNYFxiYbVmXFFkRnTvdBiIgkrZYEcRLR/Et3A+OJ5mG6OMmg+pJORS2I\nzqxaECIiSatlsr4tgW/GDwA6JOF4qlILQkSkfmppQXwOeMnMfho/TW7QZOIWRFdOLQgRkaT1myDc\n/dNEE/TNAk4xs3lm9r3EI6ug2MXUpbmYREQSV9M8S+6+jChBzCZ6HvXUJIPqSzq+iqlTLQgRkcTV\ncqPcN4DPEj3j8+fAfu7+WtKBVZJRC0JEpG5qGaReH/iSuz+RdDD9SYfxndQ5TdYnIpK0Wqb7/kY9\nAqlFJtSNciIi9bLGPOuhFk0pzcUkIlIvDZUgMqkMoDEIEZF6qGUMAjM7AtgWOAs41N2vq2GbFDCT\naKK/DuAYd59f4XOXA++4+yn9lZkJ05CFbEFjECIiSeu3BWFmPwD2BQ4mSihHm9l5NZR9ENDi7lOB\nU4D3bWNmxwKTag02kw4p5ANy6mISEUlcLS2IfYAPA4+5+1Izm040cV9/g9fTiOZvwt3nmNmU8pVm\ntiuwM3AZsHUtwY4e3QJLUxSCPG1trbVsstYa6vtfTnVRorooUV2svloSRD7+WYh/Npctq2YUsKTs\nfc7M0u6eNbP1gNOATwGH1RrsivYuyKfozHaxaNGyWjdb67S1tQ7p/S+nuihRXZSoLkpWJ1HWMkh9\nI9HDgsaZ2deAB4Ff1LDdUqA8spS7F/uGPg1MAO4i6n46wsyO6q/AdCqgkA/J6ZnUIiKJq+U+iHPM\nbB9gAbAxcJq731FD2bOA/YEbzWwXYG5ZmRcBFwHEiWHr+EFEVYVhAIUUOQ1Si4gkrpapNn5LNMXG\nqe7euRJl3wpMN7PZQEA0uH0EMNLdL1+lYMMU5FPkUAtCRCRptYxBXAEcDpxvZvcAP3f3+/vbKH5+\nxHG9Fs+r8Lmf1RADAGEqpRaEiEid1DLd953u/nlgK6Krks4zswWJR1ZBOgwo5FPkUYIQEUlarTfK\nfZBoRtdPA68CFyQZVF/SYdSCKJAnX8iTChrqRnARkYZSyxjEXCBLNA6xl7u/nnhUfUiHAeSjpJDN\n52gKlSBERJJSSwviCHef2//HkhfGLQiIJuxrCjODHJGIyNqrzwRhZpe7+5eBi8ys0Hu9u++VaGQV\nFMcgQFN+i4gkrVoL4rL45+l1iKMm6VTPFoSIiCSnzwTh7o/GLw9195PK15nZtcADSQZWSVg+BqG7\nqUVEElWti+lKYDNgipltW7YqA4xOOrBK0qFaECIi9VKti2kGsAlwIVE3UxAvzwLPJRpVH9JhqnsM\nQglCRCRZfV4n6u4vx3dMTwMmufsDwHyi6b9X1Ce8nsJU0N2C0CC1iEiyarmR4AZgvfj1snib6xOL\nqIqe90EoQYiIJKmW+yA+4O4HALj7UuA7ZvZEsmFV1vs+CBERSU4tLYiCmXU/FtTMtga6kgupb+X3\nQei51CIiyaqlBfFfwL1m9hrRQPUE4POJRtWHVBAQFFsQuUHJUSIiQ0YtDwz6o5ltDEwiajm4u3ck\nHlkFQRAQEALQpRaEiEii+u1iMrOxwCXAj4B/ApfGywZFGCcIjUGIiCSrljGIK4C/A+OJrmJ6nWhm\n10ERBkoQIiL1UEuC2DR+RGje3Tvd/VRgw4Tj6lNKCUJEpC5qSRBZMxsNFADMbEsgn2hUVYREU3x3\n5Fbm8dgiIrKyarmK6TTgfmBjM/stMBX4QpJBVZOmiQ5gRXZQbuYWERkyarmK6W4zewTYGQiBY939\nzcQj60NIEwDtOSUIEZEkVZvN9cvufrmZfbfXqu3NDGA5cLu7P59kgL1l4gShFoSISLKqjUEEZT8r\n/dkAuCfR6CpIB8UEMSi3YoiIDBnVHhh0WfzzDDPLAMUpNl5w9xxApUeRJi0TpinkU+piEhFJWL9j\nEGa2G9F9D28RtThazexwd3/E3b9RZbsUMBOYDHQAx7j7/LL1hwCnEF0ddYO7X1hTwGEKcmnau5Qg\nRESSVMtlrucD+7n7FHf/MHA40YG/PwcBLe4+lSgRnFdcYWYh8ANgb6Krok4wswm1BByGAYVcmhVq\nQYiIJKqWBIG7zy17/Qi1XR47Dbg73mYOMKWsjBywjbsvIbpDOwRqurEhnYpaEBqDEBFJVrWrmHaL\nX84zs58CVxE9bvRzwN9qKHsUsKTsfc7M0u6eBXD3rJkdTDTP051EV0VV1dbWyojhTRQ603TmOxk3\nfjhhKqwhlLVPW1vrYIewxlBdlKguSlQXq69aS+CMXu9/WPa6lsHppUD531CqmByK3P2W+Oa7nwFH\nAtdUK3DRomXksjnIRWG/9sbbDM8MryGUtUtbWyuLFi0b7DDWCKqLEtVFieqiZHUSZbWrmPZc5VIj\ns4D9gRvNbBegu5vKzEYBtwP/x907zGw5NU7fEYYBhRVR2O3ZjiGZIERE6qHqWELczfS/wEfiRX8H\nznT3h2oo+1ZgupnNJrpv4mgzOwIYGd+AdwPwoJl1AU9R4wyxxauYAA1Ui4gkqNoYxF7A9cAM4GtA\nE7Ar8Csz+5y731+tYHfPA8f1WjyvbP3lwOUrHXAqRSFXbEEoQYiIJKVaC+I0ostbnyhb9riZzSG6\n9HW3ypslKwyDUgtCCUJEJDHVLnMd1Ss5AODujwLjkgupujAMKGSVIEREklYtQYw0s/e1MOJltdwH\nkYh0KgX5uIspp3shRESSUi1B3AOcU74gvgP6fKL7FgZFOr6TGtSCEBFJUrWWwP8At5vZfKB49/QU\n4Bng4DrEVlE6TIG6mEREElftPojlwF5mtjvRZa4F4AJ3f7hewVUShmVXMamLSUQkMbU8Ue4B4IE6\nxFKTtK5iEhGpi5om61uTpMtaEEoQIiLJabgEEaYCXcUkIlIHDZcg0mEKCilC0qzItg92OCIia60G\nTBDRo7LTQZOeCSEikqCGSxBhKgo5TZOeSy0ikqCGSxDNmSjkkIwGqUVEEtRwCWJMa3P0IpemK58l\nm89W30BERFZJ4yWIkVGCyHUVnwmhcQgRkSQ0XIIY1pympSkk2xmFrm4mEZFkNFyCABjb2kxHR3Q1\nU7uuZBIRSUTDJoiujhBA90KIiCSkMRPEyOay51KrBSEikoTGTBCjmvVcahGRhDVmgihvQShBiIgk\noiETxJjW5rIZXdXFJCKShIZMEGNbSy0ITbchIpKMBk0QLXomhIhIwhoyQbQOz5AqZADdByEikpR+\nHzm6qswsBcwEJgMdwDHuPr9s/eHA14AsMBc4wd3ztZSdCgJGtwynHVihLiYRkUQk2YI4CGhx96nA\nKcB5xRVmNgyYAezp7h8FRgOfXJnCx44YAUB7lxKEiEgSEmtBANOAuwHcfY6ZTSlb1wHs6u7vlcXR\n75G+ra21+/W6E1r5Zy6ko9DRY/lQMRT3uS+qixLVRYnqYvUlmSBGAUvK3ufMLO3u2bgr6U0AMzsJ\nGAnc21+BixYt6349PBNCNs2y9vd6LB8K2tpah9w+90V1UaK6KFFdlKxOokwyQSwFyiNLuXv3wxvi\nMYofAlsBh7h7YWUKH9vaTOHttMYgREQSkuQYxCxgXwAz24VoILrcZUALcFBZV1PNivdCdOZ1FZOI\nSBKSbEHcCkw3s9lAABxtZkcQdSc9AnwReAj4s5kBXOjut9Za+Nj4buo8ebpyXWTCzMDvgYjIEJZY\ngojHGY7rtXhe2evVar2Mae05o6sShIjIwGrIG+UAxo5s0oyuIiIJatgEkUmHZILo+dSabkNEZOA1\nbIIAaElHCUItCBGRgdfQCWJEZhgAS1as9EVQIiLSj4ZOEK3NwwF4Z/m7gxyJiMjap6ETxKiWKEH8\n+73lgxyJiMjap6ETxJhh0YR9S9rVxSQiMtAaOkGMi2d0XdahFoSIyEBr6AQxoTWa6ml5p65iEhEZ\naA2dICaOihKELnMVERl4DZ0gxg4fCUQJolBYqclgRUSkHw2dIJrTTVCAjlwHL7y2pP8NRESkZg2d\nIFJBiuHpEaRGLOWOJx4f7HBERNYqDZ0gAA6zAwhSeea3/IHHFvpghyMistZo+ATxkXV3YOrIT0CQ\n55p51/LcO88PdkgiImuFhk8QAIfuMI3g5Snk83kuffIanlk8r/+NRESkqrUiQbQ0pZm2yfZ0PP9h\nKARcPvc6nlms7iYRkdWxViQIgL123ID80gmMeXsaAXD53GuVJEREVsNakyDWGTucSZuN57UXW5g+\n/pDuJPHUomcGOzQRkYa01iQIgEP32JxMOsXdf1rOEZt/joCou+n+V2cNdmgiIg1nrUoQG00cyRF7\nb8nyFVnuva+dr25/LCObRnDTC7dx0/O3kS/kBztEEZGGsVYlCIDdJq/PLh9ch38sXMojj3Xy3zue\nxHoj1uH+12Yx88mrWdz+r8EOUUSkIax1CSIIAv7vPsY644Zz999e4YWXOvjGjifwwfHGc+88z4y/\nnsufXnmEL/OHAAALfUlEQVSQXD432KGKiKzR1roEATCsOc0JB21HS1PIFb97ltlPLuaED32BI7f5\nDJkwwy3z7+CcRy7ikTefUKIQEelDkNQsqGaWAmYCk4EO4Bh3n9/rM8OBe4Evunt/d7cVFi1atlIx\nLHhjGeff9CRLl3ey39QPcPBum7G86z1umX8Hf33jUQBGN7UybYNdmLLO9rQNm0AQBCv1HYOhra2V\nla2LtZXqokR1UaK6KGlra13lg1qSCeJg4AB3P8rMdgG+5e4Hlq2fAvwU2BDYI4kEAfDWv9s5/9dP\n8Oa/2tlpm4kcMX0rRg1v4q33FvHga3/hL68/wopc9DyJ8S3j2Gb8Vmw5ZjPWH7Eu6wxvI0yFK/2d\nSWtra+XNt5bQlc/SmeukM9dFV76TznwXXbksXfmu+E+WbPmfQo5cPkc2nyNXyJIr5MkVcuQL+fhP\ngXwhT6FQoECh+2clAQEEkCKI3gUBqSBFQEAqiN+TipbF61IEpIKQVPF9jz+lz/fYJt4uiD8TlR+t\nDwgYO2YES5e0E8TfHS2ne33veINivOX7UnZSUP770HPPC/H/C0T/lX+uQLRZr6Vln4vK7X4XLytf\nUuj+mp6fKpbVO5r3/72MGtXCkiXtFWIfGNWOMn2dWAVVt6q2fVDhVe3ljx4zrLsuBsQqVGhfvzsD\n/DX92mPrKWtkgvgx8Dd3/1X8/p/uvkHZ+o8CrwDXA8cllSAAlr7XycW/eYp/LFzKiJY0h+yxObtN\nXp9UELAiu4JH33qSZxc7896Z350sAMIgpG34BMY2j2Z00yhGNbcyIjOc5rCZYWEzmbCJdCokDELC\nIEXpn3J0YM11H3TjA3P8syvfRbb7Z5aufLb7gN6Z66Qr30Vnris+4BcP/NH74vqufHaV6kJEhpYb\nP3PpGpkgrgRudvffx+9fATZz92yvz91PjQlideLJ5fLcOfslfv77ebR3ZNlyozEcvOcW7LztemTS\n0VBMLp/jhcUv8493XubVJQt5dclC/rnsTd7rGsAzkZUUpkKawgwtYTNN6SaawyaawgzN3a+baEpn\nop9hpsefdCpNU5ghk8qQCdOkU8U/IelUSCoo/kwRpnqe0ZfOxCsMUxVbGPHrfLG1EbdAylsj739d\n+pMrf51///q+yim2bIrv6fEa8oUChUK+9A+mEMUanf33PK+rdJYX9HX2Gp/ldrdNgtInozPgUuul\nvKzobdDrdf/b0eeyHqX3jL1nwO/bt1XX969f+SGkd+329bmeJVcru8q6RM63B1atLage2wxwN/dB\n2+yzygWmBzKQXpYCrWXvU72Tw8pa3T7FqVtPZJsNR/OrP73A3557i3Oue4RRI5rYbfJ6TLGJbDhx\nJOODiYwfN5GdxpW268h1sqRjKUs7l9Gebac9u4KOXAcduU7y+aibJlfoOdgdBKm4yyTqEikemMMg\n7D5QZ1Lp6OCdykSviwfzVIamME1TqqliF9eA9q8Wbw1ZybH68n9xNXXCBQzs8SqmvuYS1UWJ6mJg\nJJkgZgH7AzfGYxBzE/yumo0Z2cxxB27HgdOWc//jC5k193XumL2AO2YvYNTwDB/cZBxbbjSGDSaM\nYIO2EYxoydAcNjFx+AQmDp8w2OGLiNRNkgniVmC6mc0mOnc82syOAEa6++UJfm9N1hs/gsP33pKD\nd9+Mx59fxNwX3+HZBe8w59k3mfPsm92fGzWiiXGtzYxtbWZMazOtwzIMb04zrCXNsKY0mXSKpnSK\nTCYkHQaEqRTpMBqoTaXKf8YDp/HP4nuAVBAP+Ba7H4Koq6A0sDrwzU4Rkf4kNgaRgFUepK75CwoF\nFr69nJdeX8bCt5fz2tvv8sbi9/j3u51kc4M/TUep3zp6VylnDHweqb3AWr97QEMMgr47t9cmNVRa\nEARV++yHEtVFyc0/2H+NHINoOEEQsEHbSDZoG9ljeaFQYPmKLP9e1sHyFV28tyLLex1ZVnTm6Mzm\n6OzK05nNkcsVyOUKZPN58vlC9KdQIF8gHsCFQj4eMC1E64v/hKOBVUoDqoXSAF2+uIBo2C+dDunq\nysXve4wQDqiVKa7238WBDTKdDslm1+6bHWut23QmJNu1dtdFrVQXA0MJogZBEDByWIaRwzKDHQqg\nAbhyqosS1UWJ6mJgrJVTbYiIyOpTghARkYqUIEREpCIlCBERqUgJQkREKlKCEBGRipQgRESkIiUI\nERGpqJGm2hARkTpSC0JERCpSghARkYqUIEREpCIlCBERqUgJQkREKlKCEBGRipQgRESkojX+gUFm\nlgJmApOBDuAYd58/uFHVj5llgKuBTYBmYAbwLPAzosezPQ18xd0H/5modWJmE4FHgelAliFaF2b2\nLeAAoInod+QBhmBdxL8j1xL9juSALzEE/12Y2c7AOe6+h5ltQYX9N7MvAccS1c8Md7+jWpmN0II4\nCGhx96nAKcB5gxxPvX0eWOzuHwM+DvwE+DHwnXhZABw4iPHVVXwwuAxojxcNybowsz2AXYGPArsD\nGzFE6wLYF0i7+67AmcBZDLG6MLNvAlcCLfGi9+2/ma0LfJXo38w+wNlm1lyt3EZIENOAuwHcfQ4w\nZXDDqbubgP+NXwdEmX9HorNFgN8Dew9CXIPlXOCnwML4/VCti32AucCtwO3AHQzdungeSMe9DaOA\nLoZeXfwDOLjsfaX93wmY5e4d7r4EmA98qFqhjZAgRgFLyt7nzGyN7xobKO7+rrsvM7NW4DfAd4DA\n3YtzpCwDRg9agHVkZkcBi9z9nrLFQ7IugAlEJ0ufBo4DbgBSQ7Qu3iXqXpoHXAFcxBD7d+HuNxMl\nxqJK+9/7WNpvvTRCglgKtJa9T7l7drCCGQxmthFwH3C9u/8CKO9LbQX+PSiB1d8XgOlmdj+wPXAd\nMLFs/VCqi8XAPe7e6e4OrKDnL/tQqouTiepiK6KxymuJxmWKhlJdFFU6RvQ+lvZbL42QIGYR9TFi\nZrsQNauHDDNbB/gD8D/ufnW8+PG4DxrgE8BDgxFbvbn7bu6+u7vvATwBHAn8fijWBfAw8HEzC8xs\nfWAE8KchWhf/onRm/A6QYYj+jpSptP9/Az5mZi1mNhrYhmgAu0+N0FVzK9FZ42yiPvijBzmeevs2\nMBb4XzMrjkX8P+AiM2sCniPqehqqvgFcMdTqwt3vMLPdiH7pU8BXgJcYgnUBnA9cbWYPEbUcvg08\nwtCsi6L3/V64e87MLiJKFingVHdfUa0QTfctIiIVNUIXk4iIDAIlCBERqUgJQkREKlKCEBGRipQg\nRESkIiUIGbLMrBD/HG1mvx3Acu8re/3EQJUrUm9KECLRfSbbD2B5exRfuPtAlitSV41wo5xI0i4C\n1jezW939U2Z2JPA1ohOoR4mmSl5hZovi9+sCHyGaYns7YB3AiSZLOwfAzP7q7jubWcHdAzMbTjRP\n0GSiaRDOdffr4vmlPg6MAzYD/uDuJ9Rtz0WqUAtCJJoCeWGcHLYlep7ArvHZ/1vAf8WfmwD8IF4+\nFeiMp6HfAhgG7OvuXwVw9517fcfpRNO2bwfsBZxuZsWZNHcFDiGaWXN/M5uU0H6KrBS1IER62hPY\nEphjZhBN3fBY2fq/Arj7g2a22My+AmwdbzOySrl7AV+Mt33bzG4j6opaCsx292UAZvYiUWtCZNAp\nQYj0FAI3FlsCZjaSst8Td2+Plx9A9HCaC4FriFoXQZVye7fWg7Jyy+fDKfRTjkjdqItJJHoIU/Fg\nfT/wKTObaGYBcCnReERvexMlkmuAN4DdiJILVH5myZ+JWxBmNoHoSYn3D+A+iAw4JQgReBN4xczu\nc/cngTOIDujPEP2O/KDCNlcAh5vZ48AtwBxg03jdbcCTZtZS9vkzgXFmNhd4EDjL3cu7rkTWOJrN\nVUREKlILQkREKlKCEBGRipQgRESkIiUIERGpSAlCREQqUoIQEZGKlCBERKSi/w8G6ur3hBPf5AAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a807e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = obj_vals.plot()\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Objective value')\n",
    "ax.set_title('Objective function by iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_misclassification_errors(beta_results_df, X, y):\n",
    "    return beta_results_df.apply(lambda r: 1 - get_accuracy(r.values, X, y), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Train  Validation\n",
       "0  0.452381    0.611111\n",
       "1  0.095238    0.111111\n",
       "2  0.047619    0.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = pd.DataFrame({'Train': get_misclassification_errors(results, X_twoclasses_train, y_twoclasses_train),\n",
    "              'Validation': get_misclassification_errors(results, X_twoclasses_test, y_twoclasses_test)})\n",
    "errors[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11b30ef98>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAETCAYAAAAs4pGmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a85aa58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = errors.plot()\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Misclassification error')\n",
    "ax.set_title('Misclassification error by iteration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Corinne verification - using her code, do we see the same results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b397a23e9187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m results_corinne, thetas_corinne = corinne.fastgradalgo(np.zeros(X_train.shape[1]),\n\u001b[0m\u001b[1;32m      2\u001b[0m                                        \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                        \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                        \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                        \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "results_corinne, thetas_corinne = corinne.fastgradalgo(np.zeros(X_train.shape[1]),\n",
    "                                       np.zeros(X_train.shape[1]),\n",
    "                                       1,\n",
    "                                       0.01,\n",
    "                                       100,\n",
    "                                       X_train,\n",
    "                                       y_train)\n",
    "results_corinne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_corinne' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-222b882df108>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_corinne\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'results_corinne' is not defined"
     ]
    }
   ],
   "source": [
    "results_corinne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_corinne' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-aa9076bceed5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorinne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_corinne\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'results_corinne' is not defined"
     ]
    }
   ],
   "source": [
    "corinne.objective_plot(results_corinne, 1, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_corinne' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7013796952e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorinne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_misclassification_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_corinne\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'results_corinne' is not defined"
     ]
    }
   ],
   "source": [
    "corinne.compute_misclassification_error(results_corinne[100,:], X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-697e267bd4b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorinne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_misclassification_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "corinne.compute_misclassification_error(results.values[100,:], X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_corinne' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-0167550fc2f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_corinne\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'results_corinne' is not defined"
     ]
    }
   ],
   "source": [
    "results_corinne[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00333503,  0.00057126,  0.00208173, ..., -0.00391905,\n",
       "       -0.00173726,  0.00095118])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.values[2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-fd640dd22682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlambduh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbeta_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtheta_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m eta_init = 1/(scipy.linalg.eigh(1/len(y_train)*X_train.T.dot(X_train), \n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "lambduh = 1\n",
    "d = X_train.shape[1]\n",
    "beta_init = np.zeros(d)\n",
    "theta_init = np.zeros(d)\n",
    "eta_init = 1/(scipy.linalg.eigh(1/len(y_train)*X_train.T.dot(X_train), \n",
    "                                eigvals=(d-1, d-1), eigvals_only=True)[0]+lambduh)\n",
    "maxiter = 300\n",
    "#betas_grad = corinne.graddescent(beta_init, lambduh, eta_init, maxiter, X_train, y_train)\n",
    "betas_fastgrad, thetas_fastgrad = corinne.fastgradalgo(beta_init, theta_init, lambduh, eta_init, maxiter,\n",
    "                                                       X_train, y_train)\n",
    "betas_fastgrad.shape\n",
    "#objective_plot(betas_grad, betas_fastgrad, lambduh, save_file='hw3_q1_part_h_output.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'betas_fastgrad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-19fc4c64c9bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbetas_fastgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'betas_fastgrad' is not defined"
     ]
    }
   ],
   "source": [
    "betas_fastgrad[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'betas_fastgrad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-f11ad1233967>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorinne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_misclassification_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetas_fastgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'betas_fastgrad' is not defined"
     ]
    }
   ],
   "source": [
    "corinne.compute_misclassification_error(betas_fastgrad[-1,:], X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so, bottom line, we get the same results from our code as we do from Corinne's code, even when we use the exact same setup/init code (for ex, that sets eta_init using X.T.dot(X)), and when we use Corinne's code that does backtracking compared to our code, above, where we're not using backtracking. I think this is good enough for me to accept that w/ a lambda of 1 at least, logistic regression is way worse than just returning negative all the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we see when we use our backtracking impl?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-240589237066>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m results = fp.fastgradalgo(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mgrad_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_gradient_logistic_regression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mobj_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_objective_logistic_regression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     lam=1, max_iter=100)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "results = fp.fastgradalgo(\n",
    "    X_train, y_train, t_init=t_init, \n",
    "    grad_func = fp.compute_gradient_logistic_regression, \n",
    "    obj_func = fp.compute_objective_logistic_regression, \n",
    "    lam=1, max_iter=100)\n",
    "results[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-4bfc3fc392a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m results = fp.fastgradalgo(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mgrad_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_gradient_logistic_regression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mobj_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_objective_logistic_regression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     lam=1, max_iter=300, t_func=fp.backtracking)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "results = fp.fastgradalgo(\n",
    "    X_train, y_train, t_init=t_init, \n",
    "    grad_func = fp.compute_gradient_logistic_regression, \n",
    "    obj_func = fp.compute_objective_logistic_regression, \n",
    "    lam=1, max_iter=300, t_func=fp.backtracking)\n",
    "results[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-7a8f8f533245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorinne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_misclassification_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "corinne.compute_misclassification_error(results.values[-1,:], X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-80b18520c499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "1 - get_accuracy(results.values[-1,:], X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we get the same results w/ our own backtracking implementation. Note again that since our stopping criteria is _only_ the number of iterations, we don't automatically get any benefit from the improved step sizes that backtracking gives us. That said, we still in theory could get to the minimum faster, which means if we're manually setting max_iter based on experimentation, then backtracking could help.\n",
    "\n",
    "Finally, it's possible that backtracking adds enough processing time that we might want to run w/ it off if we're not going to use it. \n",
    "\n",
    "Although, backtracking might not _just_ give us better steps sizes leading to quicker convergence. It seems like it could also help us avoid the case where we _don't_ converge, if it keeps us from using a static/single step size that at some point means we're moving back and forth on our objective value without decreasing.\n",
    "\n",
    "Bottom line, if i care, I should probably benchmark, and watch for non-convergence being fixed when we use backtracking. I'll keep that in mind.\n",
    "\n",
    "Also, separately, it seems like my impl is way faster than Corinne's - I can run w/ 300 iterations in just a few secs while it takes her's well more than 10-20s it seems, anecdotally. It might be interesting to profile and see if a) this is really the case, and b) if so, why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b9478be9d9a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorinne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "corinne.objective_plot(results.values, 1, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-ef3c85a2b25a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_objective_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcoefs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-ef3c85a2b25a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_objective_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcoefs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "[fp.compute_objective_logistic_regression(coefs, X_train, y_train, 1) for coefs in results.values][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Find the value of the regularization parameter λ using cross-validation; you may use scikit-learn’s built-in functions for this purpose. Train an L2-regularized logistic regression classiﬁer on the training set using your own fast gradient algorithm with that value of λ found by cross-validation. Plot, with diﬀerent colors, the misclassiﬁcation error on the training set and on the validation set vs iterations._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'corinne' from '/Users/andrewenfield/work/github/Data558/Kaggle/corinne.py'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(fp)\n",
    "importlib.reload(corinne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas = [10 ** exponent for exponent in range(-5,2)]\n",
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lams, scores = fp.cross_validate(10, X_twoclasses_train, y_twoclasses_train, lambdas, max_iters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1e-05, 1.0),\n",
       " (0.0001, 1.0),\n",
       " (0.001, 1.0),\n",
       " (0.01, 1.0),\n",
       " (0.1, 1.0),\n",
       " (1, 1.0),\n",
       " (10, 0.95500000000000007)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(lams, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.017001</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>-0.010831</td>\n",
       "      <td>-0.002946</td>\n",
       "      <td>-0.001579</td>\n",
       "      <td>-0.006491</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>-0.008531</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007823</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.012890</td>\n",
       "      <td>-0.031864</td>\n",
       "      <td>0.016663</td>\n",
       "      <td>0.023430</td>\n",
       "      <td>-0.024498</td>\n",
       "      <td>-0.038940</td>\n",
       "      <td>-0.007316</td>\n",
       "      <td>0.010297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.017045</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.010883</td>\n",
       "      <td>-0.010866</td>\n",
       "      <td>-0.002948</td>\n",
       "      <td>-0.001584</td>\n",
       "      <td>-0.006525</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>-0.008564</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007850</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.012931</td>\n",
       "      <td>-0.031972</td>\n",
       "      <td>0.016698</td>\n",
       "      <td>0.023511</td>\n",
       "      <td>-0.024565</td>\n",
       "      <td>-0.039056</td>\n",
       "      <td>-0.007330</td>\n",
       "      <td>0.010338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-0.017089</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.010909</td>\n",
       "      <td>-0.010900</td>\n",
       "      <td>-0.002950</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.006559</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>-0.008597</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007876</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.012973</td>\n",
       "      <td>-0.032078</td>\n",
       "      <td>0.016733</td>\n",
       "      <td>0.023592</td>\n",
       "      <td>-0.024631</td>\n",
       "      <td>-0.039172</td>\n",
       "      <td>-0.007344</td>\n",
       "      <td>0.010378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6     \\\n",
       "98  -0.017001  0.001543  0.010858 -0.010831 -0.002946 -0.001579 -0.006491   \n",
       "99  -0.017045  0.001548  0.010883 -0.010866 -0.002948 -0.001584 -0.006525   \n",
       "100 -0.017089  0.001552  0.010909 -0.010900 -0.002950 -0.001590 -0.006559   \n",
       "\n",
       "         7         8         9       ...         2038      2039      2040  \\\n",
       "98   0.002654  0.000364 -0.008531    ...    -0.007823  0.001720  0.012890   \n",
       "99   0.002646  0.000367 -0.008564    ...    -0.007850  0.001728  0.012931   \n",
       "100  0.002638  0.000370 -0.008597    ...    -0.007876  0.001735  0.012973   \n",
       "\n",
       "         2041      2042      2043      2044      2045      2046      2047  \n",
       "98  -0.031864  0.016663  0.023430 -0.024498 -0.038940 -0.007316  0.010297  \n",
       "99  -0.031972  0.016698  0.023511 -0.024565 -0.039056 -0.007330  0.010338  \n",
       "100 -0.032078  0.016733  0.023592 -0.024631 -0.039172 -0.007344  0.010378  \n",
       "\n",
       "[3 rows x 2048 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_best = fp.fastgradalgo(\n",
    "    X_twoclasses_train, y_twoclasses_train, t_init=t_init, \n",
    "    grad_func = fp.compute_gradient_logistic_regression, \n",
    "    obj_func = fp.compute_objective_logistic_regression, \n",
    "    lam=0, max_iter=max_iters)\n",
    "results_best[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.get_accuracy(fp.get_final_coefs(results_best), X_twoclasses_test, y_twoclasses_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAETCAYAAAAs4pGmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c0a3710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fp.plot_misclassification_errors_by_iteration(results_best, X_twoclasses_train, X_twoclasses_test, \n",
    "                                              y_twoclasses_train, y_twoclasses_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'corinne' from '/Users/andrewenfield/work/github/Data558/Kaggle/corinne.py'>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(fp)\n",
    "importlib.reload(corinne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Pick k = 5 classes of your choice from the dataset. You may choose any subset of 5 classes among all classes of the dataset._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_labels = ['086.Pacific_Loon','044.Frigatebird','095.Baltimore_Oriole',\n",
    "                     '154.Red_eyed_Vireo','188.Pileated_Woodpecker']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write a function that, for any class at hand, creates a training set with an equal number of examples from the class at hand and from the other classes. You may simply randomly pick the examples from the other classes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42, 2048), (42,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_incl086_train, X_incl086_test, labels_incl086_train, labels_incl086_test = fp.get_train_tst_balanced_set('086.Pacific_Loon', X_scaled, labels_train)\n",
    "y_incl086_train = np.where(labels_incl086_train == '086.Pacific_Loon', 1, -1)\n",
    "X_incl086_train.shape, y_incl086_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_For each class c, train an L2-regularized logistic regression classiﬁer using your own fast gradient algorithm with λc = 1. Display the confusion matrix. Which classes seem to be the most diﬃcult to classify?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.088888888888888906"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rate, cm, actual_labels, predicted_labels = fp.get_results_for_lambdas(classifier_labels, X_scaled, \n",
    "                                                        labels_train, np.ones(5), random_state=100)\n",
    "error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdUAAAF2CAYAAAA4MQK3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xm8nOP9//HXOVmEROorqC2qQt+2WCrWErFTWkv121ZR\nlFjKz1JVQS217/uaSi3V0sVahH5FxBI7aSLyttVW1ZIgkSDinN8f130Y6Tknk5z7nHvuyefpMY+Z\n+75n7vlcZ2I+cy33dTU0NzcTQgghhI5rLDqAEEIIoV5EUg0hhBByEkk1hBBCyEkk1RBCCCEnkVRD\nCCGEnERSDSGEEHLSvegAQgghhKJIWgD4LbACMBX4me0XK45/BzgemAWMsD28vfNFTTWEEML8bD/g\nQ9sbAIcAl7QckNQDOB/YGtgUGCrpq+2dLJJqCCGE+dmqwN0Atg2sUnFsFeAl2+/Zngk8BAxu72SR\nVEMIIczPngV2kNQgaQNgGUndsmN9gQ8qnjsN+Ep7J4s+1ZCLQzc7ou7muzxq2LZFh9ApFt9gnaJD\nCPO5nn37NXT0HGt8bdOqvnP+/toDc3qvEaQa6YPAw8BTtj/Ljk0FFq547sLA++2dLGqqIYQQSqeh\noaGqWxXWBe6zvTHwJ+CVimPPAytJWlRST1LT79j2ThY11RBCCKXT0JBbnfBF4GRJx5JqoT+VtBvQ\nx/ZVko4A7iFVQkfY/md7J4ukGkIIYb5l+11gy9l2/77i+B3AHdWeL5JqCCGE0umWX001V5FUQwgh\nlE5jJNUQQgghH1UOQupytZnqQwghhBKKmmoIIYTSaaA2a6qRVEMIIZROt8Zuc35SASKphhBCKJ3G\n6FMNIYQQ6lvUVEMIIZROQ43WCSOphhBCKJ1avaQmkmoIIYTSqdU+1UiqIYQQSicuqQkhhBByEtMU\nhtAB622zLuttuy4APXr2YJkVl+ZXu5zAR9M/Ljiyjpn12WecdcMN/HvyZGbOmsXu227LtwYOLDqs\nDmlqauKUM8/BL75Izx49Oem4YSzXf9miw+qwKFdtiT7VGiOpEbgMWBP4BNgX6ANcAcwCXgD2td0k\naTvgBKABeAr4me3minNdA3wTmAI0A92AA20/Nxfx7AVMsX27pD8AKwJXA022r5rL86xs++hqX1MG\nj9/zBI/f8wQAux66C4/e/VjpEyrA3554gr69e3PMnnsydfp0hp55ZumT6qjRY/jkk5ncMGI448ZP\n4OwLLuLic88qOqwOi3LVluhTrT07Ab1sbyhpA+BcoAn4te27JN0AbC9pNHA2MMT2u5KOAhYD3pnt\nfEfZHgmQJeGTgV2qDcb2NRWbW9pefB7LVdf6f2NZllx+Sf584c1Fh5KLIWuvzaZrrQVkv8Yaa7NJ\na248PW4cG2+0PgBrDlydic9PKjiifES5akv0qdaejYGRALYflTQIuBJYVFIDsDDwKbARMB44V9IK\nwG9sz55QZ7co8CGApNOBQUA/YJztvSUtDlwLLEKq/e4J/Bh4G1gD+Iqk24BbyGqdko4j/RDoDlxu\n+8q5KaykHwOHkWrlLwJDs0O/BVYg1a7Ps31T9kPiWWB1oC/wfduvzc37dZatfrwlI6+9t+gwcrPg\nAgsAMOPjjznp6qvZZ4cdCo6o46ZPn0Gf3n0+325s7MasWbPo3r3cXzdRrtpSq32qtRlV1+gLfFCx\n/RnwD+Ai4Hngq8BoUq10M+CXwHbAYZK+0cr5zpI0WtJ9wLbALyX1Bd6zvRUpsW4gaRngOOB22xsB\nPwfWazmJ7YNIzcA7tuyTtHb23utnz/1GlvirIqkfcBKwue2NgfeB/bPbO1kcWwKnSFose9njtrcE\n/gb8qNr36kwL9u7FEsstwUvPvlR0KLn6z3vvccRFF7HVuuuyxaBBRYfTYb17L8T0GTM+325qbqr5\nL+hqRLlqS0NDQ1W3rjY/J9WppNpoi0ZSE/AmtlcGrsu2JwNP2H7b9ofAGGCtVs53lO0htrewvYft\nfwEfAUtkfaRXkvpsewACxgLYfsT2DXOIVaQk95ntmbZ/XtmnW4UVgOdsT8u2xwCrAatkj8mOTQQG\nZM95Jrt/A+g1F+/VaQasOYAXnn6x6DByNWXqVI669FKG7rgj2224YdHh5GLtNdfgwYfHAjBu/ARW\nGjBgDq8ohyhXbWlsaKjq1tVq/+dI53kY+A7wx6xPdTzwdVKyBXgL+BbwNLB6VoN7H9gAGF7le2wH\n9Lf9g6zJd2dSc+/zwLrAOEmDge1JCbgtk4ADs8FV3YC7gB1sf1JlHP8AVpXU2/Z0YFPSQKxPgU2A\nWyQtDAzMngupi6+mLNF/CSa/NbnoMHL1+3vvZdqMGVw/ciTXjxwJwBkHHsgCPXsWHNm822LIpox9\n7Al232cozTRz8vHHFh1SLqJctSX6VGvPLcBWkh4hJbq9SU29N0qaBcwE9rP9H0nDgHuy1/3R9gRJ\nqwIHZ821bXkc+JWkMaQk9QqwNHAaMELS7tn+n5L6VVtl+1lJI0k/BBpJfartJdSfSNqyYnsIafTy\n/ZKagJeAo0kDs4ZLeghYEDgpK287py7OqJvuLzqE3B28664cvOuuRYeRq8bGRo4fdlTRYeQuyhWq\n0dDcXHMVklBCh252RN39Qzpq2LZFh9ApFt9gnaJDCPO5nn37dbia+d21dq/qO+f2Z3/XpVXa+bmm\nWmqSbiaNMq70QeUApxBCqFfdanT0byTVkrJd9TWwIYRQb+KSmhBCCKHORU01hBBC6cTcvyGEEEJO\nYu7fEEIIISdxnWoIIYSQk7xqqtnKXntlm71IM+Ytafv97PjhpFXMWuZ839+22zpfJNUQQgilk1ef\narZC2DUAki4FRrQk1Mw6wJ62n6rmfDH6N4QQQunkPfdvtlLZaq2sX70OMEzSQ9nseu3HNXfFCCGE\nEIrXUOV/c+EY0mpes7sROADYHNhYUrvrM0ZSDSGEUDp51lQlLQLI9v2z7W8ALrD9ru2ZwJ3A2u2d\nK/pUQwghlE7O16kOBu5rZX9fYIKkVYDppNrqiPZOFEk1hBBC6eR8napIq4ilDWk3oI/tqyQdA9wP\nfALcZ/uu9k4USTWEEELp5Hmdqu2zZ9v+fcXj64Hrqz1XJNUQQgilU6szKsVApRBCCCEnUVMNIYRQ\nOjGhfgghhJCTbo212dAaSTXk4uzbji06hNwNGlif68A/Of7mokMIocNqdUL92kz1IYQQQglFTTWE\nEELpNNZmRTWSagghhPKJgUohhBBCTmr1OtVIqiGEEEonaqohhBBCThprdPRvJNUQQgilEzXVEEII\nISfRpxpCCCHkpEZzaiTVEEII5RM11RBCCCEntTpNYSTVEEIIpRMDlUIIIYScRPNvCCGEkJMazamx\nSk0IIYSQl6iphlJoamrilDPPwS++SM8ePTnpuGEs13/ZosPqsB49e3DyOUezbP+l+PDDGZz2q/N5\n/dV/Fh1Wh9TrZxXlqi3dGmqzTlibUdUQSY2SrpA0VtJoSStWHNtN0thWnn+3pANaOdeJkl7IztNy\nW2+256wl6fh5iHOgpMHtHN9L0hmt7L9RUs85nPvtuY0nb6NGj+GTT2Zyw4jhHHbwgZx9wUVFh5SL\n7/1oB2ZM/4jddz6IM064kGG/PqzokDqsXj+rKFdtaWxoqOrW1aKmOmc7Ab1sbyhpA+BcYEdJawM/\nhf8a130K8D/tnO8821e0ddD2s8Cz8xDn94C3gTFz8yLbP5yH9+pyT48bx8YbrQ/AmgNXZ+LzkwqO\nKB8DVlqeh0Y/BsCrr7zBCit+reCIOq5eP6soV22p1T7VSKpztjEwEsD2o5IGSeoHnAYcBgxveaKk\nXYGmludXS9I1QL/sdjbwA9s/lPRT4GBgCjATuAm4GfgNsAiwNHApcDuwFzBT0tPAgsCpwGfAy8D+\n2VttKOk+oC9wou07Jb0KrAxcURHDd4CzgNWy1y8wN+XpDNOnz6BP7z6fbzc2dmPWrFl0717uf8KT\nnnuJwVtsyKh7HmSNtVdliSUXo7GxkaampqJDm2f1+llFuUI1ovl3zvoCH1RsNwHXAkcA01p2Slod\n2A2YU9PtERVNvxdX7B9leyPgvex8iwG/BL4FbA30zp63InCj7a2z/UfY/idwDXAe8AQp0e9ie1Pg\nn6SECzAd2BLYHrhE0uyff0sMm5Fq5xsAw4CF5lCmTte790JMnzHj8+2m5qa6+J/+1j/exfRp07nm\nzxez+TabMHH8C6VOqFC/n1WUq7Y0NDRUdetqkVTnbCqwcMV2P+DrwOXAjcCqki4A9gSWAUaRktgR\nkrZt5Xzn2R6S3Q6p2O/ZnrciMNH2DNufAY9k+/8N7CTpd8BxQI/ZXrc4sBTwR0mjSYm3pU3xIdvN\ntv9D+qHQb7bXtsTwDeBxANuvA2+0Uo4utfaaa/Dgw6n7etz4Caw0YEDBEeVjtTVX5rGHn2avXQ/h\n3jtH8+brbxUdUofV62cV5aot0adaXg+TmkP/mPWpPmB7OwBJy5NqjV8aXSLpROBt23PTDDx79eQl\nYGVJCwKfAOsBk4CfA2NtXy5pM1Kts+X1jcC7wJvAjrY/kPRd4ENgOWDdLL4lgT7Zc1uLYSLwQ+BC\nSUuTfiwUaoshmzL2sSfYfZ+hNNPMyccfW3RIuXj9H29y8CXHs98hezBt6oec8Isziw6pw+r1s4py\n1ZZujbXZqRpJdc5uAbaS9AhpUNLec/NiSasCB9s+aG5eZ/tdSWcCD5L6VBcEPgXuAC6W9EPgfWCW\npAWAp0j9sc8DhwJ3Zs27U0m16OWABSWNIiXU/W03S2rt7W/LyvwY8Br/nXy7XGNjI8cPO6roMHL3\n/nsfMPTHPy86jFzV62cV5QrVaGhubi46htAKSd2BX9o+VVIDaVTvsbbnanRvV5k5dXLd/UMaNHCX\nokPoFE+Ov7noEMJ8rmfffh2uZp6100lVfeccdesJXVqljZpqjbI9S1LvbDTvTOAxUq01hBDme3kO\nQpI0DPgu0BO4zPbVFce+QxqAOgsYYXt462dJIqnWMNvHAMcUHUcIIdSavLpUJQ0BNiJdabEQcGTF\nsR7A+aTxKNOBhyXdbvvfbcaVT1ghhBBC18nxkpptgPGk8TN3AH+tOLYK8JLt92zPBB4C2py5DiKp\nhhBCKKEck+piwCDg+8ABwA3ZOBb473kKpgFfae9k0fwbQgihdHK8omYyMCmriVrSx6Tr/f/Df89T\nsDDpqos2RVINIYRQOjkOVHoIOFTSeaSJc3qTEi2kSxRXkrQo6Xr/wcA57Z0smn9DCCGUTkNDdbc5\nsf1X4BnSLHJ3AD8DfiBpqO1PSVPS3gOMJY3+bXdtxqiphhBCmK/ZbnP2C9t3kJJtVSKphhBCKJ1a\nXaQ8kmoIIYTSifVUQwghhJwUsQJNNWqz/hxCCCGUUNRUQwghlE4RC5BXI5JqCCGE0mmM9VRDCCGE\nfNRoTo0+1RBCCCEvUVMNIYRQOtGnGkIIIeSkRnNqJNUQ2vLk+JuLDqFT/GLHU4sOIXcnXbpn0SGE\nudBz1X4dPketXqcaSTWEEELpRPNvCCGEkJMazamRVEMIIZRP1FRDCCGEnNRoTo2kGkIIoXxqdaBS\nTP4QQggh5CRqqiGEEEqndHP/SmoCmrPN2aNvtt2t06IKIYQQ2lGjrb9tJ1Xb0TQcQgihJpV29K+k\nJYAfA31INdZuwNdtxxQmIYQQQoVqaqM3A2sBuwO9ge8CTZ0ZVAghhNCehobqbl2tmqS6mO2fAHeQ\nEuwQYLXODCqEEEJoT7fGhqpuXa2apPpedm9gTdsfAD06L6QQQgihfQ0NDVXdulo1l9SMkvQn4Ejg\nXknfBD7u3LBCCCGE8pljTdX2scDRtl8DfkSqse7c2YGFEEIIbanVPtVqRv/umd1/K9s1GdgKuK4T\n4wohhBDaVNpLaoDNKh73ADYBxhBJNXShpqYmTjnzHPzii/Ts0ZOTjhvGcv2XLTqsDqvXcq23zbqs\nt+26APTo2YNlVlyaX+1yAh9NL3/P0YQXXuTS637P5aecUHQouSljmWo0p845qdreu3Jb0qLATZ0W\nURUkNQKXAWsCnwD7An2BK7LtZ4FDbTdJuhDYGJiWvXzHbLBVy7muAb4JTAEWAP4B/MT2p22894nA\n27avkHSw7UskbQssZ/uq3AtbBUmbAb8iNef3BP4MnG+7ebbn7QVMsX17G+e5BrjR9shODXgejBo9\nhk8+mckNI4YzbvwEzr7gIi4+96yiw+qwei3X4/c8weP3PAHArofuwqN3P1YXCfX6W27j7tEP0qvX\nAkWHkpuylinvmmo2J8NTwFa2J1XsP5yUY97Jdu1v222dZ15mTfoQWH4eXpennYBetjcEjgbOBa4C\nDrO9CfABsFv23HWAbWwPyW4ftHK+o7JjG2bbO1YZx3EAtkcWmFBXJ5X/x7aHAIOBVUgDy77E9jVt\nJdRa9/S4cWy80foArDlwdSY+P2kOryiHei1Xi/7fWJYll1+SsX99tOhQcrHMkktyxi9/XnQYuSpr\nmfLsU5XUA7gS+KiVw+sAe1bkkDYTKlTXp3o/X54DeAXgrupC7TQbAyMBbD8qaRDQzfYj2fGHgR0l\n/R5YCbhK0leBq22PaOukkrqRarz/ybZPBwYB/YBxlbV2SccCi0q6DHgcWJlUU74JeIP0w+NGYHVg\nbeBO28dIWhu4GPiMNIp6P9KPmztI/dV3AXcDF5H+3pOBfdr4MQBwAHCa7X9lf49Zkn4OPA2cLWkC\n8AIwE5jEF7Xsc7O/I8DvbV9YUbYeWVlWymI7zvbotv5uXWH69Bn06d3n8+3Gxm7MmjWL7t3LvSZE\nvZarxVY/3pKR195bdBi52XzD9XnrP/8pOoxclbVMOddUzyF95w1r5dg6wDBJS5K+x09v70TV1FRP\nBE7KbicA29k+cK7CzV9fUm20xWfAK5I2zba/Q5r9qTcpge0ObAscJGmNVs53lqTRwPNAf2CcpL7A\ne7a3IiXWDSQt0/IC26eSmlIPmu1cKwA/BXYATgaOANbP9gEMBw62vSmpCfu8bP+SwNa2z8qe87Os\n5nkXcFQ7f4sVgJcrd9ieCiyUNZP3AU62/cOW45J2AL4ObEBKrLtJGlhxin2Bd20PJtXaL23n/btE\n794LMX3GjM+3m5qb6iLx1Gu5ABbs3YsllluCl559qehQQh3Kq6aadYu9Y/ueNp5yI6nysjmwcfb9\n2aZqkuquth/IbmNsT5R0bRWv60xTgYUrthuBvUm/Ju4j1TTfBWYAF9qeYXsaMIrUDzu7lubfbwC3\nkZpTPwKWkPQHUrNAH6qb9OKVrFb5PvBv21Nsf8wXtf2lbT+bPR7DF7NT/cP2zOzxKsBlWaLfB/g8\nmbfin8zWHJ/9IJhpu2U6ydmbK1YBHrTdnPUdPwqsWnF8IPDt7P3/AnSXtFj7xe5ca6+5Bg8+PBaA\nceMnsNKAAUWGk5t6LRfAgDUH8MLTLxYdRqhTjQ0NVd2qsA+wVfZ9txZwXVYrRVIDcIHtd7Pv5ztJ\nLY9tam/pt9+QakGDJFVOS9gD+Eo1kXaih0m10T9K2gAYD2xP6lecLOliUhPqN4CbsibXRlKtbE4/\nCFqabrcD+tv+gaTFSdfmzv4JtfaJNbeyr9Jbktaw/XdgU1LTLHx5PmWT2vBfzy5lWqqd810ODJc0\n1vbbWdPtBdn+FrPP1fw86UfI+dnzNyL9XbbLjk8C3rR9mqQFgWNJA7kKs8WQTRn72BPsvs9Qmmnm\n5OOPLTKc3NRruQCW6L8Ek9+aXHQYoU7l1fqbtcgBkCXWA2y/ne3qC0yQtAownVRbbbMLEdrvUz2F\nlFwuJDUBtxRhFulLuUi3kH5ZPEKKa29S/999kmYA99u+C0DS9aSa2KfAdbafk7QqqQm2pen2LElH\nk5qRu5F+ucwAfiVpDClRvgIsPVscEyX9Dvi/uYh9P+CS7BfQLL5oFq50IOnXUvfsvVt7DgC2n5Z0\nDOnHQzfSj56bgbPbec1fJQ2RNJY0WviP2XlannIlKVE/QPpHdVlFrbcQjY2NHD+svVbwcqrXcgGM\nuun+okPoFEsvsQQjzjy16DByVcYydeZ1qpJ2A/rYvir7fr2fdGXJfS25pc24mpvbr1hJWphUa7o0\n61PcHzjD9ox2XxjmKzOnTp5TDT3UiF/sWK4vz2qcdGmsRFkmi6y6Vocz4n3DrqjqO2eL0w/o0ita\nqxkRcQPw9+zxNFIz6vXA9zorqPBlknoCrQ2htO39uzqeEEIoWkMBK9BUo5qk+jXb34XPR5UeJ+nZ\nObwm5CjrIB9SdBwhhFAranVGpWpG/zZXXm4haWVS/2QIIYQQKlRTUz0S+JukN7PtxUnXfYYQQgiF\naKzR5t9qln77P2A50ojU24G3SJerhBBCCIUo7SLlkr5OGvG7N7AIcCrw3U6OK4QQQmhTrfaptjf5\nw86kqZm+SboudHdguO1fd1FsIYQQQqm0V1P9C/AnYEPbLwFIKnQCgBBCCAGo2apqe0l1DWAv4CFJ\nrwJ/mMPzQwghhC5RRH9pNdocqGR7gu0jSZO5n066TvKrku6U9O0uii+EEEL4L43dGqq6dbU51jxt\nf0ZaueW2bGL5PUhJtug1VUMIIYSaMlfNubbfIa3/ed6cnhtCCCF0lhpt/Y0+0hBCCOVTq32qkVRD\nCCGUTo3m1EiqIYQQyidqqiGEEEJOajSnRlINIYRQPlFTDSGEEPJSzcKlBYikGsJ85uzbji06hNwN\nGrhL0SF0iifH31x0CDWrVmuqNZrrQwghhPKJmmoIIYTSqdVFyiOphhBCKJ0abf2NpBpCCKGEajSr\nRp9qCCGEkJOoqYYQQiidhuhTDSGEEPJRo62/kVRDCCGUT62O/o0+1RBCCCEnUVMNIYRQPjm1/0rq\nBgwHBDQDB9ieUHH8O8DxwCxghO3h7Z0vaqohhBBKp6GxoapbFb4DYPtbwHHAqS0HJPUAzge2BjYF\nhkr6ansni6QaQgihdBoaqrvNie1bgaHZ5teA9ysOrwK8ZPs92zOBh4DB7Z0vmn9DCCGUT47Df23P\nknQtsDOwa8WhvsAHFdvTgK+0d66oqYYQQiidvGqqLWz/BPgGMFxS72z3VGDhiqctzJdrsv8laqoh\nhBBKJ6/JHyTtASxr+3RgBtCU3QCeB1aStCjwIanp95z2zhdJNZRCU1MTp5x5Dn7xRXr26MlJxw1j\nuf7LFh1Wh9VjueqxTAA9evbg5HOOZtn+S/HhhzM47Vfn8/qr/yw6rA4r6+eV43qqNwO/lTQG6AEc\nBuwsqY/tqyQdAdxDatkdYbvdD73USVXS+sCZtodIWhv4K/Bidvhy2zdlz2sE7gRus33FbOe4Bvgm\nMAVoAPoB59r+bZUxPAr80ParHS/RHN/rDGCS7WtaObYw8BIwwPaHFfufAf6X9Hcq7UrOo0aP4ZNP\nZnLDiOGMGz+Bsy+4iIvPPavosDqsHstVj2UC+N6PdmDG9I/YfeeDWH6F/gz79WEcuOcvig6rw0r7\neeWUU21PJ31HtnX8DuCOas9X2qQq6ShgD2B6tmsd4Dzb57by9FOA/2nndEfZHpmdd1HgOUnX2G7O\nM+bOZHuapDtInezXAEhaB3jP9otAaRMqwNPjxrHxRusDsObA1Zn4/KSCI8pHPZarHssEMGCl5Xlo\n9GMAvPrKG6yw4tcKjigf9fp5FaW0SRV4mZQors+21wEkaUdSbfWwLNHsSmofH1nleZcEPrbdLKk/\ncBWwIPARMNT2G5JOBbYF3gAWa+9kkjYlXff0WRbz/sC1wA2275S0CqmNfifgCmAlUjPDcbZHS/oe\n6dqpd4CeQHv/4ocDp5MlVWCfLH4kvW17SUmjgf8AiwLbA5e18p5bkX6IfAxMBvax3W7nfGebPn0G\nfXr3+Xy7sbEbs2bNonv3Mv8Trs9y1WOZACY99xKDt9iQUfc8yBprr8oSSy5GY2MjTU1Nc35xDSvr\n59XYWJvjbGszqirY/gvwacWux4Ff2B4MvAKcIGl1YDfSbBjtOUvSg5JeB84Dvp/tPwe4yPaQ7PEZ\nkgaROqvXBfbkyyPDvkRSAynR7WJ7U+CfwF7Zvp9kT9sHuBrYF3g3i39H4NLswuPzgC2BbUid6O39\nTR4DFpXUX9IC2etubuWpf7C9Zfbes79nAykRt8T8ACmpF6p374WYPuOL4jc1N9X8//TVqMdy1WOZ\nAG79411Mnzada/58MZtvswkTx79Q+oQKJf68Gqu8FRBWvbjF9lMtj4G1SUlvGWAUKZkdIWnbVl57\nlO1NgAOy57+c7R8IHJPV7o4Hvkoacv2k7SbbU4Hx7cS0OLAU8MfsHFuTLi4eDawqafFs3x3Ze307\ne95fSK0ISwFTbE/OmqIfqeLvcDWwO+l6q9uzC5Zn54ryzf6eiwFTKzrjxwCrVfG+nWrtNdfgwYfH\nAjBu/ARWGjCg4IjyUY/lqscyAay25so89vDT7LXrIdx752jefP2tokPKRVk/r4aGhqpuXa0EP0eq\ndo+kQ2w/DmwBPGX7qJaDkk4E3m7pO22N7bskbUiqqX2f1NR6ju1HJK1MmqZqIvCzbPDTgsCq7cT0\nLvAmsKPtDyR9F/gwa1q+HrgIuNf2p5ImAW/aPk3SgsCxwNvAIpIWt/0OqXb85hz+Dr8jjVR7G/h5\nG89p+Xnd2ntOAfpKWsr2v7IyvzCH9+x0WwzZlLGPPcHu+wylmWZOPv7YokPKRT2Wqx7LBPD6P97k\n4EuOZ79D9mDa1A854RdnFh1SLur18ypKPSXVA4GLJX1KSihD23qipFWBg20f1Mrhk4FnJG0PHAlc\nLqkXKYEeavtZSXcDTwBvkfonW2W7SdKhwJ1ZEp5Kqj1D6vd8A1gj276SdNHxA6RZPC6zPVPSwaQf\nDFP4cnN3W+/5Xpagl8wGKLWntff8TNJ+wM2SmoD3SLX8QjU2NnL8sKPm/MSSqcdy1WOZAN5/7wOG\n/rit36nlVdbPq4haaDUamptLM8C1rkhaBrjO9hZFx5KHmVMnxz+kUJhBA0s9uL1NT45vbUhE+fXs\n26/DGfHlG2+p6jtnwA937tLsW0811cJIWg9o7cKum2xf3srzdwFOIvXhzu179QTubeWQbe8/t+cL\nIYQyaugjnJU2AAAgAElEQVRWm0OCIqnmIOvHHTIXz7+Z1kflVvPamXPzXiGEELpOJNUQQgilU6Nd\nqpFUQwghlE+tDlSKpBpCCKF8clqlJm+RVEMIIZRO1FRDCCGEvNRmTo2kGkIIoXyiphpCCCHkpCH6\nVEMIIYScRE01hBBCyEc0/4YQQgh5qc2cGkk1hBBC+USfagghhJCXaP4NIYQQ8lGrfaq1uXZOCCGE\nUEJRUw0hhFA+0acaQggh5CMGKoUQQid5cvzNRYfQKQYN3KXoEDrF3197oMPniD7VEEIIoc5FTTWE\nEEL5RPNvCCGEkI+8m38lrQ+caXvIbPsPB/YF3sl27W/bbZ0nkmoIIYTSaWjMr/dS0lHAHsD0Vg6v\nA+xp+6lqzhV9qiGEEOZ3LwNtjQpbBxgm6SFJw+Z0okiqIYQQyqexobpbFWz/Bfi0jcM3AgcAmwMb\nS9qh3bDmpgwhhBBCLWhoaKjq1hGSGoALbL9reyZwJ7B2e6+JPtUQQgjl0zXXqfYFJkhahdTfujkw\nor0XRFINIYRQOp05o5Kk3YA+tq+SdAxwP/AJcJ/tu9qNq7m5udMCC/OPmVMnxz+kEHJWxzMqdTgj\nvvvk2Kq+cxYbtGGXXtAaNdUQQgilU6vTFEZSDSGEUD6RVEMIIYR81OoqNXFJTQghhJCTqKmGEEIo\nn2j+DSGEEPKR59y/eYqkGkqhqamJU848B7/4Ij179OSk44axXP9liw6rw+qxXPVYJqjfcvXo2YOT\nzzmaZfsvxYcfzuC0X53P66/+s+iw5mx+7FOVtL6k0dnjtSQ9mk1KPEJSY7b/55KekvSEpJ1bOcc1\nkv4uabSk+yWNkbSapCUlXZY951VJveYytkWzC3yrff6jkpZv49gmku6q2B4maYqk7tn2EEm3zk18\nc/P+c3meEyUd0NHzdLVRo8fwySczuWHEcA47+EDOvuCiokPKRT2Wqx7LBPVbru/9aAdmTP+I3Xc+\niDNOuJBhvz6s6JBKrdOSaraUzm+AlmR3AvBr2xsDCwDbS1oEOBTYENgauKCN0x1le4jtzYDTgZNt\nv237oA6EuAbw3Q68vtKjwBotPxSAbYBRwLey7c2AkTm913zp6XHj2Hij9QFYc+DqTHx+UsER5aMe\ny1WPZYL6LdeAlZbnodGPAfDqK2+wwopfKzii6jQ0NFZ162qd2fzbspTO9dn2M8Ci2QTFC5NWBJgO\nvAb0zm5NVZx3UeDDrNZ2o+0NWg5I6g9cBSwIfAQMtf2GpNOBQUA/YJztvYFjgTUlDQXubuN1pwLb\nAm8Ai7UVkO1PJT1DSqyvkn6s3AhsDzwAbArsJakH8FtgBaAbcJ7tmyStDVwMfAZ8DOxn+/XW3l/S\nicDKwBLA/wCH2H5I0veBI7JzPGT7aEmLA9cCiwANwJ4Vf6sVgd+TFt99Dbg6+/sA/D/b4yW9BkwC\nJto+vP2PpXNNnz6DPr37fL7d2NiNWbNm0b17uXsw6rFc9VgmqN9yTXruJQZvsSGj7nmQNdZelSWW\nXIzGxkaamqr5Oi5QjQ5U6rQ03spSOi8CFwHPA18FRmf73wAmAk9nx1tzVtb8ex8pyfyyjeedA1yU\nrdx+DnCGpL7Ae7a3IiXWDSQtA5wKjLJ9VRuvGwQMBtYlJaOF51DkvwGbkGrcf8tuW2XN0ovYfhXY\nH3jH9kbAlsApkhYDhgMH294UuAw4bw7vP8P25sDuwKWSFgVOArbIWgKWkbQVcBxwe/Z+PwfWy14v\nUkL9se2/A8eQ5rTcDBgKXJ49rz+wW9EJFaB374WYPmPG59tNzU2l/zKD+ixXPZYJ6rdct/7xLqZP\nm841f76YzbfZhInjX6j9hAo0dGus6tbVuvIdLwQ2sb0ycB1wLrAdsBTwdWA5YCdJ67Xy2pbm3y1s\n72H7X228x0DgmKwf93hS8v4IWELSH4ArgT5Ajype9w3gSdtNtqcC4+dQvpakuh1wl+0PgA9IPwJG\nZ89ZBRgDYHsa6cfEAGBp289mzxkDrDaH9x+VneM5YElgRWBx4K6sDKtm5xUwNnvuI7ZvyF6/HbAQ\nqVbbUv59stcOJ7UGALxre/Icyt0l1l5zDR58eCwA48ZPYKUBAwqOKB/1WK56LBPUb7lWW3NlHnv4\nafba9RDuvXM0b77+VtEhlVpX/syaAkzNHr9F6m98j5T0PrHdLOl9UlPlvJoEnGP7EUkrk5pdtwP6\n2/5B1hy6M6kptIkvflS09rqJwM+yftIFSYmqTbafl7Q0qb/46Wz3PcCRwCnZ9vOkxHuLpIVJyewf\nwFuS1shqjZsCL8zh/dcBfidpdeCf2TneALbKmqL3Ap4lJdV1gXGSBpOaoz8i9V2/DFwraUhW/t/Z\n/r2kJUhNwlBdc3yX2GLIpox97Al232cozTRz8vHHFh1SLuqxXPVYJqjfcr3+jzc5+JLj2e+QPZg2\n9UNO+MWZRYdUlVqd+7dTV6mp7PeUtDFwJjALmEnqN3xV0kmk2lwT8BBwFKlGd7DtgyRdk51jZDvn\nfpXUz7g0qemyFykRHUpKOHeQkklztv9w4FXg/0i119tnf53tsZKOIyXht0hNoTtlzbhtlXcE0Gh7\nr2x7LeARoJ/tjyT1JNUEB2Tvc5Hta7M+1QtJyX4W8FPbr7T2/sBewBBSLbM38DPbT0naHTiI1Ff7\nKrB3dnwEqem4GfgpqSn5bdtXSLqS1J96JalPdRHS+oEn2r5d0tu2l2yrvJVilZoQ8her1LRt6kvP\nVfWd03fF1bo0+8bSbyWTDVR62/YVRcdSKZJqCPmLpNq2qS8/X11SHbBKLP1Wq7L+3rNaOXST7ctb\n2R9CCKET1OqE+pFU54Ltx0lNr0XGcGKR7x9CCDWhRvtUI6mGEEIonVodqBRJNYQQQvkUMFtSNSKp\nhhBCKJ1a7VOtzVQfQgghlFDUVEMIIZRP9KmGEEII+Who7FZ0CK2KpBpCCKF8ok81hBBCqG9RUw0h\nhFA6cZ1qCCGEkJe4TjWEEELIR60OVKrNVB9CCCGUUNRUQwghlE5eMypJagQuA9YEPgH2tf1SxfHv\nAMeT1roeYXt4e+eLmmoIIYTyaWio7jZnOwG9bG8IHA2c23JAUg/gfGBrYFNgqKSvtneySKohhBBK\np6GhsapbFTYGRgLYfhQYVHFsFeAl2+/Zngk8BAxu72TR/Bty0bNvv9oc3x5Cif39tQeKDqFm9fzK\nYnl95/QFPqjY/kxSd9uzWjk2DfhKeyeLmmoIIYT52VRg4YrtxiyhtnZsYeD99k4WSTWEEML87GHg\n2wCSNgDGVxx7HlhJ0qKSepKafse2d7KG5ubmzgo0hBBCqGkVo3/XABqAvYFvAn1sX1Ux+reRNPr3\n0vbOF0k1hBBCyEk0/4YQQgg5iaQaQggh5CSSagghhJCTSKohhBBCTmLyh1AKkvoDPwJ6teyz/evi\nIgpzImlR21OKjiOErhRJNZTFn4D/A94oOpCOkvQvoBlYAFiIVKZlgf/YXr7A0HIhaVPgUqCbpD8B\nr9m+uuCwOkxSX+BXwKrAC8DJ9fCjQdK5tn9edBz1IpJqKItpto8rOog82F4KQNLvgGG235C0NGni\n7npwMuki+b8Ap5Euri99UgVGAGOAG0iTq18DfLfIgHKyqqRFbLc7U1CoTiTVUBYTJP0QeIZUy8P2\nC8WG1GEr2H4DwPZbkpYrOqCcNNmeIqnZ9seSphUdUE762b4oe/yspF0LjSY/qwKTJb1D+n+r2fbS\nBcdUWpFUQ1msld1aNAObFxRLXiZKuh54HNgQeKrgePLykqTTgX6SjgZeKzqgnCwoaUnbb2fLf3Ur\nOqA82P5a0THUk0iqoRRsbyapHzAAeMX2u0XHlIOjgM2AbwA32b6t4HjycgCwL2mZrA+B/YoNJze/\nAh6R1DLJel2US9JqwBXA/wC/AybY/muxUZVXTFMYSkHS94FTSBNcrw6caPt3xUbVMZIesr1x0XHk\nRdLWbR2zfW9XxtKZJC0GTLHdVHQseZB0H7A/MBz4X+Bu24Paf1VoS9RUQ1kcAaxj+0NJCwOjSL+q\ny2yKpEMBA01Q+uTzo9m2m0kTlDcDZS4X8OVRzcCfJNXFqGYA2y9lfeDv1FEfeCEiqYayaLL9IYDt\naZI+LjqgHEzmy33FpU4+tvdueSxpdbJLT2w/W1xUuarXUc1TJO0P9M4GA8Yo4A6IpBrK4hVJ55Iu\naRgMvFxwPPNMUvdsEeT9i46lM0g6BNgNeAw4UtIfbZ9TcFh5qNdRzT8FjgHeBQYB+xQbTrnFNIWh\nLPYGXgG2JCXUMg8SuS67NzApu7U8rge7AZvYPgz4FvCDguPJS72Oal7O9tG2tycNnqvLH3tdJZJq\nKIuWEXXdgB6kvrpSsr1bdv910mjm9Wx/3fYKxUaWm4asJo7tT4FPC44nLweREulDwHTK/cOu0tWS\nVpC0PDAaiEtsOiCaf0NZXEXq67mXNJvNb4A9C42ogyRtB1wCfCCpDzDU9uhio8rFQ5L+DDwIbELq\ne6wHf7Xd5gjnEtsN+AOwIHC47fsKjqfUIqmGsljJ9uDs8a2SHik0mnycCGyQjbhcErgV2KDYkDrO\n9pGStgdWAUbYvqvomHLynqTvkub9bRmtXdpZvSQNrdh8GNgOGCBpgO2rCgqr9KL5N5RFL0kLAUha\nkPqYzWaa7XcAbL9NalIsLUk7ZPdDgWWAqcCys315l9kSwOHA5cCVpAkTymypitsHwI0V22EeRU01\nlMWFwDhJE0iXapxYbDjzTtJp2cPukv5K6qNbD/ikuKhy0S+7r8svZdubFR1DnmyfBCBpRWBd23+Q\ndAbl/7FQqEiqoRRs3yDpbmAF4B/ARwWH1BGe7R6g9FMU2r42e6iWwVj1QNKfbe9asWTf5+pk4vlr\ngZal3+4iXXu7RXHhlFsk1VAa2dqVUwAkPU6q3ZVOS/KR1B3YC1iONEPUhALDylNPSWvw5b7HmcWG\n1CG/hC+W7KtHth/N7sdIim7BDoikGsqqtJfUVLgCeAvYCniCdP3qtwuNKB8r8+WadzOphaGs/iRp\nCqkf9ZaWy4XqyPtZv/dY0g/VepnUohDxiySUVT2sBDHA9vHAx7bvAL5SdEB5sL06aa3Yr9fD9be2\nv0maFGFTYLykMyUNKDisPP2ENE7hzOw+ZlTqgKiphpqWzWAzewJtII0uLbvu2YonzdkiAaVf9UTS\nkcBQYCFJM4HL6mGKQttPA09L6gnsDJwrqZftbQsOrcNsv5sNmFsBeJS0XF+YR1FTDbWuZQq/ytsk\n0lylZXcs6frAQaQvs5OKDadjJB1GWht2HdvLkhYKWEXSL4qNLFeLA18njXD+d8Gx5CIbjb4naYao\ntYHfFhtRuUVNNdS0ihGlrZJ0i+2duyqenM2wLUmLkyYzHzynF9S4XYHBLeuM2p4q6QDSIghnFxpZ\nB2TXR+9Kaib9H9Lo2G1s18tqLhvbHizpftvXSjqw6IDKLJJqKLtFig5gbknahNR3dbik87LdjcDB\npAXYy2rm7At32/5UUtnn/n0FuB0YZvvxooPpBN0l9SJ1Q3QDPis6oDKL5t9QdmUcsPQesCSwAF/M\nYLM4aTBMmTVLWqJyh6SvUv6+4hVtD20roUq6vKsDytn5wFOkH3SPAZcVG065RU01hC5mewIwQdJw\n22+17JfUo8Cw8nAKcFfWR/cyqe/xWEre/217TgN31CWBdBLbf5L0f6QVk/5he3LRMZVZ1FRDKM53\nJL0g6RVJ/wCeKzqgjrB9P6nfcTPgNNIE7UNt/63QwEK7JG0E3A/cAdwjaa2CQyq1qKmG0pHUI1un\nE1JTaln9jHTt43HAn4DDig2n42w/BxzS2jFJl9uOQTC152JgN9sTJa1OWmZxo4JjKq2oqYZSkLSf\npJYRpHdK2gPA9vcKDKuj3rL9L2DhbB3Vupj8oR2lbiatY+/bngifd03MKDieUouaaiiLA/lirt/t\nSZdpXF9cOLn4QNJOpAE++wOLFR1QmCdlnzLzP5J+Q5p/eh2gsWW5vlhXde5FUg1l8VnLnKvZZRpl\nHPU7u32BFYFhpFVCDi42nNAaSXu2dcz2dcDWXRhOZ5iU3a9EWgP3AdKI9Hr4f6zLRVINZXGbpAeB\nx4Fvkq4bLLuWSSsGAuOApSVtbPuhAmMK/22V7H4DUtPoI8C6QA/guor+/VKRtFz28L9mULL9eheH\nUzciqYZSsH1KNj+pSF9k44qOKQc/BHqTvqTXA3oBn0l6yvbhhUbWOUrZTGp7GICkkba3b9kv6d7i\nosrFTdl9P2BhYDywGvA2qRk4zIMYqBRqmqR9s/vTgf8F1gR+kF0LWXY9gM2yL+2tgGm2BwPrFxtW\nx0haWNIpkkZI2kXSitmhsjeTLiFpEQBJ/UjJqLRsb2h7Q9KlXN+wvTVp7uZ/FhtZuUVSDbWu5d9o\naxPrl10/UmIlu180e7xAMeHkZgRpar+VSLWeqyH1hRcZVA5OBZ6V9DSpG+JXBceTl2VtTwOwPZ3U\nnxrmUTT/hlr3U9J1czuVeOL8tlwK/F3Sc6SFvc+SdAwwstiwOqyf7RGSdrf9iKS6+PFu+y+SbiMl\nnbfr4EdCi3slPQA8SWolubXgeEqtobk5BniF2iXpD8AWpGs4W6ZPawCabS9dWGA5yZoRVwResj1Z\nUjfbpZ7QXNIo4CDSHLJ7Atfb3qzYqDpO0mBSmbqRJut4zfbVxUaVD0nrkFoWJtr+e9HxlFkk1VAK\nki61/bOi48iDpOOygVd/YLbLFmzvVlBYuclm5RlOGjU7CTgoW+S71CSNAXYC/kKagvFh26Uf0CNp\nWdKk+quRulUOt/1qoUGVWDT/hpomaQfbfyU1kw6tPFbiC9PvyO5votzTLLZl22wATL1psj1FUrPt\njyVNKzqgnAwHLidNqDKE1Ae+RZEBlVkk1VDrWkZYLlloFDmquBzoSNsbFxpM5/i2pPPL3ozdipey\nUej9JB0NvFZ0QDnpZbvluu9bJdXj5VxdJpJqqGm2r80e3gCsa/sPks4ArigwrLxMkXQoqcmtCcB2\n2a99hLQ27FvZyjvNpP7vepig/QDSLFgPAdOB/YoNJzfdJQ20PV7SwKKDKbtIqqEsriVN5QdwF/XR\nRDUZWCu7QUpA9ZBUdyg6gE5yK/AbYHid1cL/HzBC0lLAW8DQOTw/tCMGKoVSkPSw7W9VbN9f1hGl\nkgbZfrLoODpLxcCXVYEXqJOBL5JWBvYhTdRxL3C17ReKjSof2Sj0AcArtt8tOp4yq4vrx8J84X1J\nQyUNlPRToMyDRM5qeSDpwiID6STDSSsIfYvUwlAXl53YnmT7KFJS7Q+Ml/Q3SaUelCXpf0lTZQ4D\nHpW0e8EhlVok1VAWPyHVfM7K7vcpNpwOqZwDtx77sHrZvt32+7Zv5YtZo0pN0naSbiItkfYMKbHu\nRfn79w8H1skmV1kbOLTgeEot+lRDKdh+V9KZpC/oBtKF6mVtpqr3PpfZB77US3l3By6z/UDlTkkn\nFhNObppsfwhge5qkj4sOqMwiqYZSkHQ1sCFpVZcFSXPLblBoUPNumeya24aKx0Cpr72t1DLwZWnS\n5Oz1MvDlJ8BekrYg1VYn2H7X9i0Fx9VRr0g6l3Sd6mDg5YLjKbVIqqEs1iTN+HIlcAzw52LD6ZDf\n88Wk5ZWP64LtZ0jrjdabK0ijY7cCngCuA75daET52BvYn1Su54Gjiw2n3CKphrKYbLtZUu+sKbjo\neOaZ7ZOKjqEzSTqV1Of9ebNvPczTDAywvW+2kPwd2QQQpSXpFuBuYKTtS4uOp15EUg1l8ZSkI0mT\nCtxIagKuK5IusX1w0XHkYHtgedufFB1IzrpLWgzSmrFkE3aU2AXAZsC1kr4CjCatkPRAHX52XSaS\naigF28dkX2QfkSYzf7zgkDpDvdQWngF6AfX2xXws8DCpuf5RSj5KNhtw9QCApAWAbUlrxN4M9Ckw\ntFKLyR9CTZO0CnAK6brUX9r+d8Eh5U7S1nUyPSEAkn4OnExaoLxlmb4Vio0qP5IWB9613Zxt72/7\nyoLDmmvZOrffIs2AtSXwAWlSi7sr5qcOcylqqqHWXQ6cASxKukb1J8WG03Gzr7YDHCHpPKib0b8/\nAL4OvF90IJ3B9juz7foBaQBd2bwD3AfcCJxqe2rB8dSFSKqh1jXZHgkgqcwTPlTaCViE1H/VACxA\nfY0Afg2YPh/1yzXM+Sk16Rxga9IlUKtIuisbuR06IJJqKJN6mQFse1KTdnfgBGBInY0I7g+8LOmV\nbLteVqlpSyn70GyfDpyeDVLaGjg4W2D+Odv18gO2y0VSDbWun6StSbWBRbPHQHmXScv64o6V9D3S\n9ba9Cg4pbz8oOoAwV74GfJU0OGkm5R/VXKhIqqHWPQ38KHv8TMXj0i+TZvsvkgzsUXQseZC0r+3f\nkNYdnb32dkwBIXWVUjb/SrqTNPf0M8DfgBNsTyo2qvKLpBpqmu29i46hM9meIKkuJpwH3sjuZ/9i\nLmXzaAtJy7V1zPbrwFFdGE6eTgcetT2rtYNlHdVctEiqoZTKPFGCpEcqNhtIg0Q2AChz36Pte7KH\n61Z+NpKuI03pV1Y3Zff9gIWBCaSVkv4NfNP2E0UF1hG2H5rDU8o6qrlQkVRDWZV5ooRLSNP4HQpM\nB/7AF83apSXpZ8BxpL7vXbLdDcDE4qLqONsbwufT+u2ZreTSm/S51bNSNmsXLZJqqHmS+tmeLGlF\nYC1gou3SflHb/r2k50nX3R4BfGT7tYLD6rBs/thLJR1j+7Si4+kEy9qeBmB7uqR6ugyqNaVuti9K\nJNVQ0yRdArwq6d+kxZTHAEdK+rPtc4qNbt7ZfkbSHsC1wOJFx5OHikkt3p19gos6mdTiXkkPAE8C\n6wG3FhxPqEGRVEOtW8f2wZLGAJtkNYTuwFjSxeulI2kF4DxgHVJtoF82EvNw2y8UGlzHtFVzq4sa\nj+1jJa0DrARcNx9M5RfNv/MgkmqoeZIWJS1KvhCpD7Iv5f4f/jfAMNuPtezIBir9ljQXaylVTmCR\nNY32IH1O9bDsG5KWIbWWLAH8SVKvys+wbOp4VHOhIqmGWvdr0koa44Fxkp4AVgeGFRpVx/zXl7Ht\nR8u8RmwlSVcDGwK9SUv0vQJsUGhQ+bgKOJe0kssYUtN9mctVl6OaixZJNdQ023dLehDYCPgrMBl4\nupVJzctknKQRpLl/PyB9oX0b+HuhUeVnTWA10uUYx5BmjaoHC9oeJek425b0cdEBdcR8PKq5U9XL\nXKqhvm2a3f8Z+A5wfntNVyVwEHAHsD6wK6lW99dsfz2YnE3F2Nv2u0UHk6OPJW0DdMua60udVCt8\naVQz9bW4Q5eLmmqoaZJ+Q5obd2HgJOB64C1gOLBNgaHNsyzh3JLd6tFTko4E3pJ0I6kJuB4MJQ2O\nWww4kjQdYz2IUc05ikXKQ02TNMb2YEkNpNUzVs323297s4LDC22QtDDwEbAd8HidLi6/ne27i44j\nDxWjmp+fD0Y1d6qoqYZa1yNrclsM+KqklYEPSSNLQw2R1A3YEfgPMA64DOhJGmRWWpL2Ak4j/UjY\nlTTwajiwClD6pFpvo5qLFkk11LoDgONJK2kcCowGpgD7FhhTaN21pEto+gLLAreTJtkfAWxeYFwd\ndQRp4NVSpNG/SwO3AT8uMqgc1duo5kLFQKVQ66YB3UjJ9VTgU+BVoJ4GwNSLFWz/GNgJWMj2CdlS\ncGVfn3OK7feyqTFXBY62fbztT4sOLCcL2h5FWkze1M8ArEJETTXUut+QvsQeb9lRDxMl1KmPAWx/\nJumfFfvL/uO98kfBa/XSj1qhXkc1FyKSaqh1vSoTKtTXRAl1pp+krUlNwItWPi42rA7rJ2kr0o+D\nvlm5ALB9b3Fh5aZeRzUXIpJqqHX1PlFCPXmaL5awe2a2x2X2NLBb9riyXM1APSTVbW3/sGVD0v8D\nLiownlKLS2pCTcsupdkJ2Jg0AGYq8DBwS3a9ZwhhHkj6EfBdYDNgVLa7ERhoe7XCAiu5qKmGmjYf\nTJRQ9yRdYvvgouPIWx2UayTwL9Lcv1dm+5qAlwuLqA5EUg0hdLZLiw6gk5S6XLbfI12iNnq2VYW+\nRpq1LMyDaP4N4f+3d78xV9Z1HMffRAizmywoa9aYtfCTszkqWnVngpqQ5BroyiwsMGOR3c1aBf0f\ns03qQQtDbICpaav1xOqBsSIx00JmCLiyr6WzZkzdstAUFwQ9+P1O3N4i4n1+8ruv6/q8npzrXOec\n6/6eJ+d7//5c368VIWlyr4aspDeQCutvjYi760ZWlqQ5LdmgBDytq9DRwL0R4ftUR8kjVTMr5afA\n6ZIWk5oD3AR8QtI1EbGubmijJ2nJiFOfkfQtgIhYWyGk0traVaiKpt8/ZmZjz0eB0yJiGTAb+Ejd\ncPo2H1gEvJJUVWlifmxLN5e2dhWqwiNVMytlsqQpwIPA3nxuL6n+b5O9B/g66ffya8DsiFhRN6Si\n2tpVqAonVTMr5TbSFPB00hTp5fnc96tG1ac8ivuSpHNJU6OTKodUVER8UdIAqZLSWcCWZ/mIHYI3\nKplZUfne4qOBJwBFxJ8qh1SMpJOACyJiee1YSsldar5B7lID7HCXmtHzmqqZFSPpg6RbTdaQSt8d\nXzWgAiS9Lz++iLS2OlPSyjy6a4O1pE5CE0hdalbVDafZnFTNrAhJq0g9Rn9G6nm7C5gn6dKqgfVv\naX5cBfwTGAIeICWjNnCXmoK8pmpmpcyIiFn5eIOkX0bEmZJurRpVOdMjotfH925J51SNphx3qSnI\nI1UzK2WSpLcCSDoV2CvppaSiAk12gqRPA3skvRFA0kyav6u5ZwmwmANdapYe+u12KB6pmlkpHwfW\n5o0v9wIXku5R/UrVqPp3NvBm4B7gZEn3AatpePKR1Pun4GHgwzVjaRMnVTMrZRfwd1JRhGnAr4C7\ngBtrBtWviNgGbAOuGna6DWX8gtS+blx+ZNjxa2sF1XROqmZWynpg+fCm8nmN7mrgHdWi6pOkTaQq\nSsK/eWoAAASwSURBVE8TEYNHOJxiIuI1tWNoIydVMytl0vCEChARmyXViqeU5cA6YAEHKkU1Xq91\nnaTfcWCkCjT7n4XanFTNrJTtkr5H6tO5C5gMzAN2VI2qTxFxu6TrgJMjok19fXu3On2gahQt44pK\nZlZErqQ0HzgFeDHwKKlM4Q251J+NIZJOJNU0fgxYFhEPVQ6pFZxUzcw6SNLNwEpgCjA3IpreTWhM\n8PSvmVk37YuIDQCSLqwdTFu4+IOZmTkXFOKRqplZN02VNId0b+qUfAxARPyiXljN5qRqZtZNW4Hz\n8/Gdw473A06qo+SNSmZmZoV4Ht3MzP5P0uraMTSZk6qZmQ13Re0AmsxrqmZm1mtn95KI2Fg7libz\nmqqZWQdJmg98G/gvcDmptvG/gIiIZTVjazKPVM3MuukLwAxgALgDmBYR/5F0W92wms1J1cysm8aT\n6v4C7ONAp5rxdcJpBydVM7Nu+iFwH3A/sAnYIGk3qcuQjZLXVM3MOkrSMcDj+elZwCMR4enfPviW\nGjOz7joFOJ2UC+YCSyVNqxtSs3n618ysgyStByaRmsmvAK4DdgLrSAnWRsEjVTOzbjohIhaSGssf\nExFrIuInwFGV42o0j1TNzLppgqS5wMuAV0h6PWk38IS6YTWbk6qZWTctBb5K6lBzMfBr4B/Ax2oG\n1XTe/WtmZlaIR6pmZh0kaRMw8WCvRcTgEQ6nNZxUzcy6aTlpp+8CYG/lWFrD079mZh0l6XPAXyLi\nhtqxtIWTqpmZWSG+T9XMzKwQJ1UzM7NCvFHJrOMkHQ/cA/yR1P7rKFK5usUR8cAorrcImB0RiyTd\nCFwUETuf4b0rgI0R8ZvncP39ETHuucZldiQ4qZoZwM6ImNF7Iuky4DuknaGjFhHznuUts0htx8xa\nwUnVzA7mFuC9ku4HbgdmAO8E3g1cQlo6+j1wcUQ8KekC4MvAo8BfgX8D5M/PBh4EriB1RdkDXEq6\nR3ImsF7SAmA3cCUwFXgCGIqIO/NI+npgANj8fH5ps355TdXMnkLSBOA8oNdX8+cRIeDlpBJ2g3lU\n+zDwWUnHAd8ETgXeTup6MtIQKSmeCLyLVB7vR8AdpOnhu4Brgc9HxJuAJfl1gNXANflvutenjWke\nqZoZwHGStuXjicAWUnGAOaSRKsBpwHRgsyRIa69bgUHgtxHxEICk64EzRlx/FrA2IvaRRq0n5feS\nHweAtwBX984BA5Kmkka65+dzPwCuKvGFzZ4PTqpmBiPWVHtygtudn44HfhwRn8qvDZB+Q87gqbNe\nB6vOs2fEdV8H/G3YqfHAkyPWdV8NPELaPNW7/n5g32F/K7MjzNO/Zna4bgYWSDpW0jjS+uclwK3A\n2yS9StILSFPHI90CvF/SOEnHkjqiTCQl4BdGxC7gz5IWAkg6M38GYCOwMB+fwzPUqzUbC5xUzeyw\nRMR2YAVwE/AH0u/HyjztO0RKfltIm5VGWgM8DmzP7xuKiMeADcB3JQ0CHwIukrQDuAw4LyL2A58E\nzs3n55F6fpqNSS5TaGZmVohHqmZmZoU4qZqZmRXipGpmZlaIk6qZmVkhTqpmZmaFOKmamZkV4qRq\nZmZWiJOqmZlZIf8DzOhTG/pSzkgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b46b080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fp.plot_multiclass_confusion_matrix(cm, classifier_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at individual confusion matrices for each classifier, why do we always get a 0 in one corner? This means that we never have any false negatives - that is, we never predict -1 when it's actually 1. We do the other three. Why?\n",
    "\n",
    "So, this means that we never predict that it ISN'T the bird in question, when it is actually the bird in question. I tried w/ an array of thresholds from very low to very high, and while they changed some true negatives to false positives, they never changed any prediction to a false negative. Perhaps this is something that's not uncommon when you have a single 1-vs-rest classifier? For example, that classifier tends to see anything at all that looks remotely like the bird in question as the bird in question (leading to true positives when it IS the bird, and false positives when it's not), but does not - generally, or at all? - think that the bird in question is actually NOT the bird in question. I could also write the above or add in terms of precision and recall if I thought about it for a few more minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write a function that returns the ranked list of classes in terms of classiﬁcation diﬃculty using the confusion matrix. Compute the multi-class misclassiﬁcation error._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>086.Pacific_Loon</td>\n",
       "      <td>086.Pacific_Loon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>086.Pacific_Loon</td>\n",
       "      <td>086.Pacific_Loon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Actual         Predicted\n",
       "0  086.Pacific_Loon  086.Pacific_Loon\n",
       "1  086.Pacific_Loon  086.Pacific_Loon"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_df = pd.DataFrame({'Actual': actual_labels,\n",
    "                                'Predicted': predicted_labels})\n",
    "test_results_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Misclassification error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>044.Frigatebird</th>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>095.Baltimore_Oriole</th>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>086.Pacific_Loon</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154.Red_eyed_Vireo</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188.Pileated_Woodpecker</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Misclassification error\n",
       "Actual                                          \n",
       "044.Frigatebird                         0.222222\n",
       "095.Baltimore_Oriole                    0.222222\n",
       "086.Pacific_Loon                        0.000000\n",
       "154.Red_eyed_Vireo                      0.000000\n",
       "188.Pileated_Woodpecker                 0.000000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_by_class = test_results_df.groupby(['Actual']).agg(lambda g: 1 - accuracy_score(g['Actual'], g['Predicted']))\n",
    "accuracy_by_class.rename(columns={'Predicted': 'Misclassification error'}, inplace=True)\n",
    "accuracy_by_class.sort_values(['Misclassification error'], ascending=False, inplace=True)\n",
    "\n",
    "accuracy_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall multi-class misclassification error: 8.9%\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall multi-class misclassification error: {:.1%}\".format(1 - accuracy_score(actual_labels, predicted_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Find the values of the regularization parameters λ1,...,λk for the classiﬁers using a hold-out validation set strategy. Deﬁne a grid of values Λ for each parameter λc with c = 1,...,k. For each setting of the regularization parameters λ1,...,λk, where each λc can take values in Λ (independently), train all your k = 5 classiﬁers and save the multi-class misclassiﬁcation error on the validation set for each setting of the regularization parameters λ1,...,λk._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** write code that creates a grid and runs for each combo, and then that outputs and saves the misclassification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.001, 0.01, 0.1, 1]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas = [10 ** exponent for exponent in range(-3,1)]\n",
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_combinations = list(itertools.product(lambdas, repeat=5))\n",
    "len(lambda_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.001, 0.001, 0.001, 0.001, 0.001),\n",
       " (0.001, 0.001, 0.001, 0.001, 0.01),\n",
       " (0.001, 0.001, 0.001, 0.001, 0.1)]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_combinations[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.19999999999999996, 0.28888888888888886, 0.17777777777777781]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fp.get_results_for_lambdas(classifier_labels, X_scaled, labels_train, lams)[0] for lams in lambda_combinations[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "type(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Need to create train/test sets - one for each label, I think - OUTSIDE the get_results call, and pass it in, so each set of lambdas gets a chance w/ the same set of train and test data. (Might also speed things up at least a little bit, since we won't have to get new sets each time.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2017-05-28 22:34:33.608803.\n",
      "Processing lambdas with index 0...\n",
      "Finished at 2017-05-28 22:35:13.140013. Processed 10 sets of lambdas\n"
     ]
    }
   ],
   "source": [
    "print(\"Started at {}.\".format(datetime.now()))\n",
    "\n",
    "misclassification_errors = []\n",
    "\n",
    "try:\n",
    "    for index, lams in enumerate(lambda_combinations[:10]):\n",
    "        if (index % 10 == 0):\n",
    "            print('Processing lambdas with index {}...'.format(index))\n",
    "\n",
    "        error = fp.get_results_for_lambdas(classifier_labels, X_scaled, labels_train, lams)[0]\n",
    "        misclassification_errors.append(error)\n",
    "\n",
    "except:\n",
    "    raise()\n",
    "finally:\n",
    "    print(\"Finished at {}. Processed {} sets of lambdas\".format(datetime.now(), index+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.044444444444444398,\n",
       " 0.044444444444444398,\n",
       " 0.088888888888888906,\n",
       " 0.11111111111111116,\n",
       " 0.22222222222222221,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.31111111111111112,\n",
       " 0.33333333333333337]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_errors.sort()\n",
    "misclassification_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_misclassification_error_for_lambdas(lambdas):\n",
    "    return lambdas, fp.get_results_for_lambdas(classifier_labels, X_scaled, labels_train, lambdas)[0]\n",
    "\n",
    "# uses already-set (global - boo!) sets_per_labels, since this doesn't change at all for all the runs\n",
    "# and to avoid having to update to take a tuple/deal with multiple arg unpacking (for now at least)\n",
    "def get_misclassification_error_for_lambdas_with_shared_sets(lambdas):\n",
    "    return lambdas, fp.get_results_for_lambdas(classifier_labels, X_scaled, labels_train, lambdas,\n",
    "                                               sets_for_labels=sets_per_labels)[0]\n",
    "\n",
    "def create_and_run_jobs(lambda_combinations, worker_job):\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "         return executor.map(worker_job, lambda_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2017-05-29 09:47:55.743522.\n",
      "Finished at 2017-05-29 09:48:03.926263. Processed 3 sets of lambdas.\n"
     ]
    }
   ],
   "source": [
    "print(\"Started at {}.\".format(datetime.now()))\n",
    "\n",
    "all_results = []\n",
    "\n",
    "results = create_and_run_jobs(lambda_combinations[:3], get_misclassification_error_for_lambdas)\n",
    "for result in results:\n",
    "    all_results.append(result)\n",
    "    \n",
    "print(\"Finished at {}. Processed {} sets of lambdas.\".format(datetime.now(), len(all_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0.001, 0.001, 0.001, 0.001, 0.001), 0.26666666666666672),\n",
       " ((0.001, 0.001, 0.001, 0.001, 0.01), 0.26666666666666672),\n",
       " ((0.001, 0.001, 0.001, 0.001, 0.1), 0.17777777777777781)]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pickle.dump(all_results, open('all_results', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.022222222222222254,\n",
       " 0.022222222222222254,\n",
       " 0.022222222222222254,\n",
       " 0.022222222222222254,\n",
       " 0.044444444444444398,\n",
       " 0.044444444444444398,\n",
       " 0.044444444444444398,\n",
       " 0.044444444444444398,\n",
       " 0.044444444444444398,\n",
       " 0.044444444444444398,\n",
       " 0.044444444444444398,\n",
       " 0.044444444444444398,\n",
       " 0.044444444444444398,\n",
       " 0.044444444444444398,\n",
       " 0.044444444444444398,\n",
       " 0.044444444444444398,\n",
       " 0.044444444444444398,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.066666666666666652,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.088888888888888906,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.1333333333333333,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.15555555555555556,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.17777777777777781,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.19999999999999996,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.22222222222222221,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.24444444444444446,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.26666666666666672,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.28888888888888886,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.31111111111111112,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.35555555555555551,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.37777777777777777,\n",
       " 0.40000000000000002,\n",
       " 0.40000000000000002,\n",
       " 0.40000000000000002,\n",
       " 0.40000000000000002,\n",
       " 0.40000000000000002,\n",
       " 0.40000000000000002,\n",
       " 0.40000000000000002,\n",
       " 0.40000000000000002,\n",
       " 0.40000000000000002,\n",
       " 0.40000000000000002,\n",
       " 0.40000000000000002,\n",
       " 0.40000000000000002,\n",
       " 0.40000000000000002,\n",
       " 0.40000000000000002,\n",
       " 0.40000000000000002,\n",
       " 0.40000000000000002,\n",
       " 0.40000000000000002,\n",
       " 0.40000000000000002,\n",
       " 0.42222222222222228,\n",
       " 0.42222222222222228,\n",
       " 0.42222222222222228,\n",
       " 0.42222222222222228,\n",
       " 0.42222222222222228,\n",
       " ...]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = [error for _, error in all_results]\n",
    "foo.sort()\n",
    "foo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, with the ability to generate the train-test sets just once, so that a) most importantly, each fastgradalgo run gets to use the same particular set of train/test data, so one doesn't have an easier or harder time than another, and b) it might be at least a bit faster since we only have to generate the train-test data once rather than for each of the runs for a set of five lambdas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the worker func requires the train-test sets to pointed to by the sets_per_labels variable - argh, global state (see above)\n",
    "sets_per_labels = [fp.get_train_tst_balanced_set(classifier_label, X_scaled, labels_train) for classifier_label in classifier_labels]\n",
    "len(sets_per_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2017-05-29 09:56:55.569739.\n"
     ]
    }
   ],
   "source": [
    "print(\"Started at {}.\".format(datetime.now()))\n",
    "\n",
    "all_results_shared_sets = []\n",
    "\n",
    "results = create_and_run_jobs(lambda_combinations, get_misclassification_error_for_lambdas_with_shared_sets)\n",
    "for result in results:\n",
    "    all_results_shared_sets.append(result)\n",
    "    \n",
    "print(\"Finished at {}. Processed {} sets of lambdas.\".format(datetime.now(), len(all_results_shared_sets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_results_shared_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.26666666666666672, 0.088888888888888906]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo = fp.get_results_for_lambdas(classifier_labels, X_scaled, \n",
    "                                                        labels_train, np.ones(5), random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.088888888888888906"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3125"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3125"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(itertools.product([1,2,3,4,5],repeat=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0001, 0.001, 0.01, 0.1, 1, 10]"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas = [10 ** exponent for exponent in range(-4,2)]\n",
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.19999999999999996, array([[6, 0, 3, 0, 0],\n",
       "        [0, 9, 0, 0, 0],\n",
       "        [0, 0, 8, 1, 0],\n",
       "        [0, 1, 0, 8, 0],\n",
       "        [1, 0, 3, 0, 5]]))"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.get_results_for_lambdas(classifier_labels, X_scaled, labels_train, lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15555555555555556, array([[5, 0, 0, 0, 4],\n",
       "        [0, 7, 0, 0, 2],\n",
       "        [0, 0, 8, 0, 1],\n",
       "        [0, 0, 0, 9, 0],\n",
       "        [0, 0, 0, 0, 9]]))"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.get_results_for_lambdas(classifier_labels, X_scaled, labels_train, np.zeros(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.066666666666666652, array([[9, 0, 0, 0, 0],\n",
       "        [1, 6, 0, 0, 2],\n",
       "        [0, 0, 9, 0, 0],\n",
       "        [0, 0, 0, 9, 0],\n",
       "        [0, 0, 0, 0, 9]]))"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.get_results_for_lambdas(classifier_labels, X_scaled, labels_train, np.ones(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0001, 0.001, 0.01, 0.1, 1, 10]"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas = [10 ** exponent for exponent in range(-4,2)]\n",
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('086.Pacific_Loon', 0.0001),\n",
       " ('044.Frigatebird', 0.001),\n",
       " ('095.Baltimore_Oriole', 0.01),\n",
       " ('154.Red_eyed_Vireo', 0.1),\n",
       " ('188.Pileated_Woodpecker', 1)]"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(label, lam) for label, lam in zip(classifier_labels, lambdas)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'corinne' from '/Users/andrewenfield/work/github/Data558/Kaggle/corinne.py'>"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(fp)\n",
    "importlib.reload(corinne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Find the optimal value of the regularization parameters λ1,...,λk based on the validation error. Display the confusion matrix for this setting of the regularization parameters._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
