{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-23T15:58:00.446415",
     "start_time": "2017-05-23T15:58:00.416914"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# general\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "import importlib\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 8, 5\n",
    "\n",
    "# first used in exercise one\n",
    "import linearsvm as svm\n",
    "from sklearn import preprocessing # for scale\n",
    "import scipy.linalg\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-23T15:58:59.893842",
     "start_time": "2017-05-23T15:58:59.885841"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importlib.reload(svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note: Per the request in the \"Collaboration policy\" note, I've discussed at least part of this assignment with many of the MS employees in the class, including Abhishek, Geoff, Suman, and Charles. (Different weeks/different assignments have different people, depending upon who attends our study groups, but I'll probably just include this blurb w/ each homework since it's generally correct.) I've also gotten input from the discussion board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Compute the gradient ∇F(β) of F._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gradient](gradient.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Consider the Spam dataset from The Elements of Statistical Learning. Standardize the data, if you have not done so already._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-23T15:42:34.580430",
     "start_time": "2017-05-23T15:42:34.535387"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 58)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam = pd.read_table('data/spam.data', sep=' ', header=None)\n",
    "spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-23T15:45:14.064578",
     "start_time": "2017-05-23T15:45:14.035080"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7    8     9  ...   48     49  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.0  0.00 ...  0.0  0.000   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.0  0.94 ...  0.0  0.132   \n",
       "\n",
       "    50     51    52     53     54   55    56  57  \n",
       "0  0.0  0.778  0.00  0.000  3.756   61   278   1  \n",
       "1  0.0  0.372  0.18  0.048  5.114  101  1028   1  \n",
       "\n",
       "[2 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and the train/test split info\n",
    "spam_traintest = pd.read_table('data/spam.traintest', \n",
    "                               header=None, names=['TestIndicator'])\n",
    "spam_traintest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TestIndicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TestIndicator\n",
       "0              1\n",
       "1              0\n",
       "2              1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_traintest[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert label 0/1 to -1/1\n",
    "spam[57] = spam[57].apply(lambda v: -1 if v == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-23T16:00:56.385119",
     "start_time": "2017-05-23T16:00:56.373119"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    2788\n",
       " 1    1813\n",
       "Name: 57, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam[57].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-23T15:44:30.698503",
     "start_time": "2017-05-23T15:44:30.686501"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4601, 57), (4601,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = spam.values[:,0:57]\n",
    "y = spam.values[:,57]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-23T15:51:50.509463",
     "start_time": "2017-05-23T15:51:50.496968"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 57)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled = preprocessing.scale(X)\n",
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-23T15:52:05.561225",
     "start_time": "2017-05-23T15:52:05.552723"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3065, 57), (1536, 57), (3065,), (1536,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_train = X_scaled[spam_traintest['TestIndicator'] == 0, :]\n",
    "X_scaled_test = X_scaled[spam_traintest['TestIndicator'] == 1, :]\n",
    "y_train = y[spam_traintest['TestIndicator'] == 0]\n",
    "y_test = y[spam_traintest['TestIndicator'] == 1]\n",
    "\n",
    "X_scaled_train.shape, X_scaled_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write a function mylinearsvm that implements the fast gradient algorithm to train the linear support vector machine with the squared hinge loss. The function takes as input the initial step-size value for the backtracking rule and a maximum number of iterations._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I implemented the mylinearsvm function, and all of the supporting functions including the gradient and objective functions, in the file linearsvm.py, which I imported into this notebook with the alias svm. Instead of creating a function named mylinearsvm, I just call my fastgradalgo function and pass in references to my linear SVM gradient and objective functions. I also include my (relatively minimal) unit tests, in linearsvm-test.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Train your linear support vector machine with the squared hinge loss on the the Spam dataset for the λ = 1. Report your misclassiﬁcation error for this value of λ._ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown below, my misclassification error is 9.6% (corresponding to an accuracy of 90.4%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_init = 0.01\n",
    "max_iters = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.004707</td>\n",
       "      <td>-0.017785</td>\n",
       "      <td>0.041067</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.054787</td>\n",
       "      <td>0.113581</td>\n",
       "      <td>0.060567</td>\n",
       "      <td>0.043423</td>\n",
       "      <td>0.024483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023849</td>\n",
       "      <td>-0.023435</td>\n",
       "      <td>-0.017923</td>\n",
       "      <td>-0.011564</td>\n",
       "      <td>0.057493</td>\n",
       "      <td>0.105909</td>\n",
       "      <td>0.022018</td>\n",
       "      <td>0.024618</td>\n",
       "      <td>0.054175</td>\n",
       "      <td>0.056466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.004707</td>\n",
       "      <td>-0.017785</td>\n",
       "      <td>0.041067</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.054787</td>\n",
       "      <td>0.113581</td>\n",
       "      <td>0.060567</td>\n",
       "      <td>0.043423</td>\n",
       "      <td>0.024483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023849</td>\n",
       "      <td>-0.023435</td>\n",
       "      <td>-0.017923</td>\n",
       "      <td>-0.011564</td>\n",
       "      <td>0.057493</td>\n",
       "      <td>0.105909</td>\n",
       "      <td>0.022018</td>\n",
       "      <td>0.024618</td>\n",
       "      <td>0.054175</td>\n",
       "      <td>0.056466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.004707</td>\n",
       "      <td>-0.017785</td>\n",
       "      <td>0.041067</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.054787</td>\n",
       "      <td>0.113581</td>\n",
       "      <td>0.060567</td>\n",
       "      <td>0.043423</td>\n",
       "      <td>0.024483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023849</td>\n",
       "      <td>-0.023435</td>\n",
       "      <td>-0.017923</td>\n",
       "      <td>-0.011564</td>\n",
       "      <td>0.057493</td>\n",
       "      <td>0.105909</td>\n",
       "      <td>0.022018</td>\n",
       "      <td>0.024618</td>\n",
       "      <td>0.054175</td>\n",
       "      <td>0.056466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "998   0.004707 -0.017785  0.041067  0.022033  0.063291  0.054787  0.113581   \n",
       "999   0.004707 -0.017785  0.041067  0.022033  0.063291  0.054787  0.113581   \n",
       "1000  0.004707 -0.017785  0.041067  0.022033  0.063291  0.054787  0.113581   \n",
       "\n",
       "            7         8         9     ...           47        48        49  \\\n",
       "998   0.060567  0.043423  0.024483    ...    -0.023849 -0.023435 -0.017923   \n",
       "999   0.060567  0.043423  0.024483    ...    -0.023849 -0.023435 -0.017923   \n",
       "1000  0.060567  0.043423  0.024483    ...    -0.023849 -0.023435 -0.017923   \n",
       "\n",
       "            50        51        52        53        54        55        56  \n",
       "998  -0.011564  0.057493  0.105909  0.022018  0.024618  0.054175  0.056466  \n",
       "999  -0.011564  0.057493  0.105909  0.022018  0.024618  0.054175  0.056466  \n",
       "1000 -0.011564  0.057493  0.105909  0.022018  0.024618  0.054175  0.056466  \n",
       "\n",
       "[3 rows x 57 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = svm.fastgradalgo(\n",
    "    X_scaled_train, y_train, t_init=t_init, \n",
    "    grad_func = svm.compute_linearsvm_gradient, \n",
    "    obj_func = svm.compute_linearsvm_objective, \n",
    "    lam=1, max_iter=max_iters)\n",
    "results[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00470651, -0.01778492,  0.04106708,  0.02203334,  0.06329117,\n",
       "         0.05478699,  0.11358142,  0.06056665,  0.04342264,  0.02448297,\n",
       "         0.04303622, -0.01988106,  0.01359624,  0.01196979,  0.03772923,\n",
       "         0.10491026,  0.06641436,  0.0520275 ,  0.05424548,  0.04369458,\n",
       "         0.09507983,  0.04484736,  0.09426391,  0.06432963, -0.05355806,\n",
       "        -0.03838683, -0.04609687, -0.01992538, -0.01869907, -0.02547454,\n",
       "        -0.00801355, -0.00424814, -0.02992379, -0.00442401, -0.01561272,\n",
       "        -0.00625731, -0.03108503, -0.01270518, -0.02830545,  0.00894927,\n",
       "        -0.01613486, -0.03341811, -0.0241412 , -0.02498623, -0.0456691 ,\n",
       "        -0.04229804, -0.01272238, -0.02384934, -0.02343515, -0.01792313,\n",
       "        -0.01156379,  0.05749315,  0.10590906,  0.02201775,  0.02461781,\n",
       "         0.05417492,  0.05646572]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.get_final_coefs(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(beta_coefs, X, y_actual, threshold=0):\n",
    "    \"\"\"\n",
    "    Return the classification accuracy given a set of coefficients, in \n",
    "    beta_coefs, and observations, in X, compared to actual/known values \n",
    "    in y_actual. The threshold parameter defines the value above which the\n",
    "    predicted value is considered a positive example.\n",
    "    \"\"\"\n",
    "    y_pred = X.dot(beta_coefs.T).ravel() # ravel to convert to vector\n",
    "    # convert to -1 or +1 depending on threshold\n",
    "    y_thresholded = np.where(y_pred > threshold, 1, -1)\n",
    "    return accuracy_score(y_actual, y_thresholded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.4%\n",
      "Misclassification error: 9.6%\n"
     ]
    }
   ],
   "source": [
    "# note use of the held out test data to get the performance metrics\n",
    "accuracy = get_accuracy(svm.get_final_coefs(results), X_scaled_test, y_test)\n",
    "print(\"Accuracy: {0:.1%}\".format(accuracy))\n",
    "print(\"Misclassification error: {0:.1%}\".format(1 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Run cross-validation to ﬁnd the optimal value of λ. Report your misclassiﬁcation error for that value of λ._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown below, my optimal value of $\\lambda$ is zero. The misclassification error from the test/hold out set using coefficients from a model trained with a lambda of zero is 8.4% (which corresponds to an accuracy of 91.6%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_test_single_fold(X_full, y_full, lam, train_index, test_index):\n",
    "    \"\"\"\n",
    "    Train using the data identified by the indices in train_index, and then test\n",
    "    (and return accuracy) using the data identified by the indices in test_index.\n",
    "    \"\"\"\n",
    "    beta_vals = svm.fastgradalgo(\n",
    "        X_full[train_index], y_full[train_index], t_init=t_init, \n",
    "        grad_func = svm.compute_linearsvm_gradient, \n",
    "        obj_func = svm.compute_linearsvm_objective, \n",
    "        lam=lam, max_iter=max_iters)\n",
    "    \n",
    "    final_coefs = svm.get_final_coefs(beta_vals)\n",
    "    \n",
    "    return get_accuracy(final_coefs, X_full[test_index], y_full[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_test_for_all_folds(X_full, y_full, train_indices, \n",
    "                                 test_indices, lam):\n",
    "    \"\"\"\n",
    "    Train and test for all folds - for now, 10 folds, hard-coded. Return \n",
    "    the mean of the set of accuracy scores from all folds.\n",
    "    \"\"\"\n",
    "    accuracy_scores = [train_and_test_single_fold(X_full, y_full, lam,\n",
    "                                       train_indices[i], \n",
    "                                       test_indices[i]) for i in range(10)]\n",
    "    return(np.mean(accuracy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get arrays with 10 sets of test and train indices - one for each fold\n",
    "kf = KFold(10, shuffle=True, random_state=42)\n",
    "\n",
    "train_indices_list = []\n",
    "test_indices_list = []\n",
    "for train_index, test_index in kf.split(X_scaled_train):\n",
    "    train_indices_list.append(train_index)\n",
    "    test_indices_list.append(test_index)\n",
    "    \n",
    "train_indices = np.array(train_indices_list)\n",
    "test_indices = np.array(test_indices_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas = [10 ** exponent for exponent in range(-5,2)]\n",
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1e-05, 0.9161567775861702),\n",
       " (0.0001, 0.91583104468714738),\n",
       " (0.001, 0.91583210917374558),\n",
       " (0.01, 0.91191692746588315),\n",
       " (0.1, 0.91027974707798442),\n",
       " (1, 0.90929083902833663),\n",
       " (10, 0.8939569095825084)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and finally, do 10-fold cross validation for each value of lambda, and\n",
    "# show the mean of each set's classification accuracy\n",
    "accuracy_values_by_lambda = [train_and_test_for_all_folds(X_scaled_train, \n",
    "                                y_train, train_indices, test_indices, \n",
    "                                lam) for lam in lambdas]\n",
    "list(zip(lambdas, accuracy_values_by_lambda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_lambda = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.005867</td>\n",
       "      <td>-0.027225</td>\n",
       "      <td>0.050431</td>\n",
       "      <td>4.278140</td>\n",
       "      <td>0.102371</td>\n",
       "      <td>0.071049</td>\n",
       "      <td>0.308368</td>\n",
       "      <td>0.091116</td>\n",
       "      <td>0.047523</td>\n",
       "      <td>0.021685</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189956</td>\n",
       "      <td>-0.179221</td>\n",
       "      <td>-0.062239</td>\n",
       "      <td>-0.016350</td>\n",
       "      <td>0.073153</td>\n",
       "      <td>0.617278</td>\n",
       "      <td>0.258428</td>\n",
       "      <td>-0.144212</td>\n",
       "      <td>0.473202</td>\n",
       "      <td>0.094983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.005865</td>\n",
       "      <td>-0.027226</td>\n",
       "      <td>0.050431</td>\n",
       "      <td>4.284186</td>\n",
       "      <td>0.102372</td>\n",
       "      <td>0.071052</td>\n",
       "      <td>0.308329</td>\n",
       "      <td>0.091115</td>\n",
       "      <td>0.047523</td>\n",
       "      <td>0.021686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190031</td>\n",
       "      <td>-0.179161</td>\n",
       "      <td>-0.062229</td>\n",
       "      <td>-0.016322</td>\n",
       "      <td>0.073152</td>\n",
       "      <td>0.617243</td>\n",
       "      <td>0.258434</td>\n",
       "      <td>-0.144224</td>\n",
       "      <td>0.473228</td>\n",
       "      <td>0.094986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>-0.005863</td>\n",
       "      <td>-0.027228</td>\n",
       "      <td>0.050432</td>\n",
       "      <td>4.290233</td>\n",
       "      <td>0.102373</td>\n",
       "      <td>0.071055</td>\n",
       "      <td>0.308291</td>\n",
       "      <td>0.091114</td>\n",
       "      <td>0.047523</td>\n",
       "      <td>0.021687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190106</td>\n",
       "      <td>-0.179100</td>\n",
       "      <td>-0.062220</td>\n",
       "      <td>-0.016295</td>\n",
       "      <td>0.073151</td>\n",
       "      <td>0.617208</td>\n",
       "      <td>0.258439</td>\n",
       "      <td>-0.144237</td>\n",
       "      <td>0.473254</td>\n",
       "      <td>0.094989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "998  -0.005867 -0.027225  0.050431  4.278140  0.102371  0.071049  0.308368   \n",
       "999  -0.005865 -0.027226  0.050431  4.284186  0.102372  0.071052  0.308329   \n",
       "1000 -0.005863 -0.027228  0.050432  4.290233  0.102373  0.071055  0.308291   \n",
       "\n",
       "            7         8         9     ...           47        48        49  \\\n",
       "998   0.091116  0.047523  0.021685    ...    -0.189956 -0.179221 -0.062239   \n",
       "999   0.091115  0.047523  0.021686    ...    -0.190031 -0.179161 -0.062229   \n",
       "1000  0.091114  0.047523  0.021687    ...    -0.190106 -0.179100 -0.062220   \n",
       "\n",
       "            50        51        52        53        54        55        56  \n",
       "998  -0.016350  0.073153  0.617278  0.258428 -0.144212  0.473202  0.094983  \n",
       "999  -0.016322  0.073152  0.617243  0.258434 -0.144224  0.473228  0.094986  \n",
       "1000 -0.016295  0.073151  0.617208  0.258439 -0.144237  0.473254  0.094989  \n",
       "\n",
       "[3 rows x 57 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train with best lambda\n",
    "results_best_lambda = svm.fastgradalgo(\n",
    "    X_scaled_train, y_train, t_init=t_init, \n",
    "    grad_func = svm.compute_linearsvm_gradient, \n",
    "    obj_func = svm.compute_linearsvm_objective, \n",
    "    lam=best_lambda, max_iter=max_iters)\n",
    "results_best_lambda[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.6%\n",
      "Misclassification error: 8.4%\n"
     ]
    }
   ],
   "source": [
    "accuracy = get_accuracy(svm.get_final_coefs(results_best_lambda), \n",
    "                        X_scaled_test, y_test)\n",
    "print(\"Accuracy: {0:.1%}\".format(accuracy))\n",
    "print(\"Misclassification error: {0:.1%}\".format(1 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
